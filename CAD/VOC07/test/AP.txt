[11/16 15:39:00] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 15:39:01] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 15:39:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '8', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD', 'MODEL.WEIGHTS', './data/dino_RN50_pretrain_d2_format.pkl'], resume=False)
[11/16 15:39:01] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "SyncBN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "SyncBN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 16
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 15:39:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_test_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: SyncBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: SyncBN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./data/dino_RN50_pretrain_d2_format.pkl
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 15:39:01] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 15:39:01] d2.utils.env INFO: Using a generated random seed 1146890
[11/16 15:39:01] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 15:39:04] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 15:39:04] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:39:04] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 5011         |
|            |              |[0m
[11/16 15:39:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:39:04] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:39:04] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:39:04] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:39:04] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/16 15:39:04] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:39:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:39:04] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:39:04] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:39:04] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:39:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./data/dino_RN50_pretrain_d2_format.pkl ...
[11/16 15:39:04] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[11/16 15:39:04] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model              | Names in Checkpoint                                                                                        | Shapes                                             |
|:----------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| backbone.res2.0.conv1.*     | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |
| backbone.res2.0.conv2.*     | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.0.conv3.*     | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.0.shortcut.*  | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.1.conv1.*     | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.1.conv2.*     | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.1.conv3.*     | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.2.conv1.*     | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.2.conv2.*     | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.2.conv3.*     | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res3.0.conv1.*     | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| backbone.res3.0.conv2.*     | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.0.conv3.*     | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.0.shortcut.*  | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| backbone.res3.1.conv1.*     | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.1.conv2.*     | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.1.conv3.*     | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.2.conv1.*     | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.2.conv2.*     | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.2.conv3.*     | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.3.conv1.*     | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.3.conv2.*     | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.3.conv3.*     | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res4.0.conv1.*     | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| backbone.res4.0.conv2.*     | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.0.conv3.*     | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.0.shortcut.*  | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.res4.1.conv1.*     | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.1.conv2.*     | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.1.conv3.*     | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.2.conv1.*     | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.2.conv2.*     | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.2.conv3.*     | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.3.conv1.*     | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.3.conv2.*     | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.3.conv3.*     | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.4.conv1.*     | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.4.conv2.*     | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.4.conv3.*     | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.5.conv1.*     | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.5.conv2.*     | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.5.conv3.*     | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.stem.conv1.*       | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,7,7)                 |
| roi_heads.res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| roi_heads.res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| roi_heads.res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
[11/16 15:39:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.res5.norm.{bias, running_mean, running_var, weight}[0m
[11/16 15:39:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
[11/16 15:39:04] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 15:39:05] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 497, in run_step
    self._trainer.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 154, in forward
    features = self.backbone(images.tensor)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 449, in forward
    x = stage(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 195, in forward
    out = self.conv1(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/layers/wrappers.py", line 88, in forward
    x = self.norm(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 519, in forward
    world_size = torch.distributed.get_world_size(process_group)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 638, in get_world_size
    return _get_group_size(group)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 220, in _get_group_size
    _check_default_pg()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 211, in _check_default_pg
    "Default process group is not initialized"
AssertionError: Default process group is not initialized
[11/16 15:39:05] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/16 15:39:05] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 3445M
[11/16 15:43:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 15:43:44] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 15:43:44] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '8', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD', 'MODEL.WEIGHTS', './data/dino_RN50_pretrain_d2_format.pkl'], resume=False)
[11/16 15:43:44] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "BN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "BN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 16
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 15:43:44] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_test_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: BN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./data/dino_RN50_pretrain_d2_format.pkl
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 15:43:44] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 15:43:44] d2.utils.env INFO: Using a generated random seed 44875375
[11/16 15:43:45] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 15:43:47] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 15:43:47] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:43:47] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 5011         |
|            |              |[0m
[11/16 15:43:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:43:47] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:43:47] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:43:47] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:43:47] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/16 15:43:47] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:43:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:43:47] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:43:47] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:43:47] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:43:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./data/dino_RN50_pretrain_d2_format.pkl ...
[11/16 15:43:47] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[11/16 15:43:47] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model              | Names in Checkpoint                                                                                        | Shapes                                             |
|:----------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| backbone.res2.0.conv1.*     | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |
| backbone.res2.0.conv2.*     | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.0.conv3.*     | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.0.shortcut.*  | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.1.conv1.*     | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.1.conv2.*     | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.1.conv3.*     | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.2.conv1.*     | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.2.conv2.*     | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.2.conv3.*     | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res3.0.conv1.*     | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| backbone.res3.0.conv2.*     | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.0.conv3.*     | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.0.shortcut.*  | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| backbone.res3.1.conv1.*     | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.1.conv2.*     | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.1.conv3.*     | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.2.conv1.*     | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.2.conv2.*     | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.2.conv3.*     | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.3.conv1.*     | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.3.conv2.*     | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.3.conv3.*     | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res4.0.conv1.*     | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| backbone.res4.0.conv2.*     | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.0.conv3.*     | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.0.shortcut.*  | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.res4.1.conv1.*     | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.1.conv2.*     | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.1.conv3.*     | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.2.conv1.*     | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.2.conv2.*     | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.2.conv3.*     | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.3.conv1.*     | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.3.conv2.*     | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.3.conv3.*     | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.4.conv1.*     | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.4.conv2.*     | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.4.conv3.*     | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.5.conv1.*     | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.5.conv2.*     | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.5.conv3.*     | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.stem.conv1.*       | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,7,7)                 |
| roi_heads.res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| roi_heads.res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| roi_heads.res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
[11/16 15:43:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.res5.norm.{bias, running_mean, running_var, weight}[0m
[11/16 15:43:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
[11/16 15:43:47] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 15:43:48] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 497, in run_step
    self._trainer.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 154, in forward
    features = self.backbone(images.tensor)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 449, in forward
    x = stage(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 201, in forward
    out = self.conv3(out)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/layers/wrappers.py", line 85, in forward
    x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups
RuntimeError: CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 10.76 GiB total capacity; 9.36 GiB already allocated; 64.56 MiB free; 9.60 GiB reserved in total by PyTorch)
[11/16 15:43:48] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/16 15:43:48] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 9588M
[11/16 15:44:20] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 15:44:20] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 15:44:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '8', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD', 'MODEL.WEIGHTS', './data/dino_RN50_pretrain_d2_format.pkl'], resume=False)
[11/16 15:44:20] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "BN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "BN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 8
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 15:44:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_test_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: BN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./data/dino_RN50_pretrain_d2_format.pkl
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 15:44:20] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 15:44:20] d2.utils.env INFO: Using a generated random seed 20789712
[11/16 15:44:21] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 15:44:23] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 15:44:23] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:44:23] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 5011         |
|            |              |[0m
[11/16 15:44:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:44:23] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:44:23] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:44:23] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:44:23] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/16 15:44:23] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:44:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:44:23] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:44:23] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:44:23] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:44:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./data/dino_RN50_pretrain_d2_format.pkl ...
[11/16 15:44:23] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[11/16 15:44:23] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model              | Names in Checkpoint                                                                                        | Shapes                                             |
|:----------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| backbone.res2.0.conv1.*     | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |
| backbone.res2.0.conv2.*     | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.0.conv3.*     | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.0.shortcut.*  | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.1.conv1.*     | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.1.conv2.*     | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.1.conv3.*     | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.2.conv1.*     | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.2.conv2.*     | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.2.conv3.*     | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res3.0.conv1.*     | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| backbone.res3.0.conv2.*     | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.0.conv3.*     | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.0.shortcut.*  | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| backbone.res3.1.conv1.*     | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.1.conv2.*     | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.1.conv3.*     | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.2.conv1.*     | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.2.conv2.*     | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.2.conv3.*     | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.3.conv1.*     | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.3.conv2.*     | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.3.conv3.*     | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res4.0.conv1.*     | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| backbone.res4.0.conv2.*     | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.0.conv3.*     | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.0.shortcut.*  | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.res4.1.conv1.*     | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.1.conv2.*     | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.1.conv3.*     | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.2.conv1.*     | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.2.conv2.*     | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.2.conv3.*     | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.3.conv1.*     | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.3.conv2.*     | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.3.conv3.*     | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.4.conv1.*     | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.4.conv2.*     | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.4.conv3.*     | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.5.conv1.*     | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.5.conv2.*     | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.5.conv3.*     | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.stem.conv1.*       | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,7,7)                 |
| roi_heads.res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| roi_heads.res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| roi_heads.res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
[11/16 15:44:23] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.res5.norm.{bias, running_mean, running_var, weight}[0m
[11/16 15:44:23] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
[11/16 15:44:23] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 15:44:24] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 497, in run_step
    self._trainer.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 163, in forward
    _, detector_losses = self.roi_heads(images, features, proposals, gt_instances)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/roi_heads/roi_heads.py", line 472, in forward
    [features[f] for f in self.in_features], proposal_boxes
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/roi_heads/roi_heads.py", line 457, in _shared_roi_transform
    return self.res5(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 195, in forward
    out = self.conv1(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/layers/wrappers.py", line 85, in forward
    x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups
RuntimeError: CUDA out of memory. Tried to allocate 1.53 GiB (GPU 0; 10.76 GiB total capacity; 8.46 GiB already allocated; 238.56 MiB free; 9.43 GiB reserved in total by PyTorch)
[11/16 15:44:24] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/16 15:44:24] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 8664M
[11/16 15:44:35] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 15:44:35] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 15:44:35] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '8', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD', 'MODEL.WEIGHTS', './data/dino_RN50_pretrain_d2_format.pkl'], resume=False)
[11/16 15:44:35] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "BN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "BN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 4
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 15:44:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_test_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: BN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./data/dino_RN50_pretrain_d2_format.pkl
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 15:44:36] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 15:44:36] d2.utils.env INFO: Using a generated random seed 36156939
[11/16 15:44:36] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 15:44:38] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 15:44:38] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:44:38] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 5011         |
|            |              |[0m
[11/16 15:44:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:44:38] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:44:38] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:44:38] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:44:38] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/16 15:44:38] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:44:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:44:38] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:44:38] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:44:38] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:44:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./data/dino_RN50_pretrain_d2_format.pkl ...
[11/16 15:44:39] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[11/16 15:44:39] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model              | Names in Checkpoint                                                                                        | Shapes                                             |
|:----------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| backbone.res2.0.conv1.*     | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |
| backbone.res2.0.conv2.*     | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.0.conv3.*     | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.0.shortcut.*  | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.1.conv1.*     | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.1.conv2.*     | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.1.conv3.*     | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.2.conv1.*     | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.2.conv2.*     | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.2.conv3.*     | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res3.0.conv1.*     | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| backbone.res3.0.conv2.*     | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.0.conv3.*     | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.0.shortcut.*  | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| backbone.res3.1.conv1.*     | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.1.conv2.*     | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.1.conv3.*     | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.2.conv1.*     | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.2.conv2.*     | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.2.conv3.*     | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.3.conv1.*     | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.3.conv2.*     | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.3.conv3.*     | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res4.0.conv1.*     | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| backbone.res4.0.conv2.*     | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.0.conv3.*     | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.0.shortcut.*  | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.res4.1.conv1.*     | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.1.conv2.*     | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.1.conv3.*     | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.2.conv1.*     | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.2.conv2.*     | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.2.conv3.*     | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.3.conv1.*     | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.3.conv2.*     | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.3.conv3.*     | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.4.conv1.*     | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.4.conv2.*     | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.4.conv3.*     | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.5.conv1.*     | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.5.conv2.*     | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.5.conv3.*     | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.stem.conv1.*       | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,7,7)                 |
| roi_heads.res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| roi_heads.res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| roi_heads.res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
[11/16 15:44:39] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.res5.norm.{bias, running_mean, running_var, weight}[0m
[11/16 15:44:39] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
[11/16 15:44:39] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 15:44:39] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 497, in run_step
    self._trainer.run_step()
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 163, in forward
    _, detector_losses = self.roi_heads(images, features, proposals, gt_instances)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/roi_heads/roi_heads.py", line 472, in forward
    [features[f] for f in self.in_features], proposal_boxes
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/roi_heads/roi_heads.py", line 457, in _shared_roi_transform
    return self.res5(x)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/modeling/backbone/resnet.py", line 201, in forward
    out = self.conv3(out)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2/layers/wrappers.py", line 85, in forward
    x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 10.76 GiB total capacity; 9.03 GiB already allocated; 526.56 MiB free; 9.15 GiB reserved in total by PyTorch)
[11/16 15:44:39] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/16 15:44:39] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 9250M
[11/16 15:45:05] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 15:45:06] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 15:45:06] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '8', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD', 'MODEL.WEIGHTS', './data/dino_RN50_pretrain_d2_format.pkl'], resume=False)
[11/16 15:45:06] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "BN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "BN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 2
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 15:45:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_test_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: BN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./data/dino_RN50_pretrain_d2_format.pkl
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 15:45:06] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 15:45:06] d2.utils.env INFO: Using a generated random seed 6508748
[11/16 15:45:06] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 15:45:08] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 15:45:08] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:45:08] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 5011         |
|            |              |[0m
[11/16 15:45:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:45:08] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:45:08] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:45:08] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:45:08] d2.solver.build WARNING: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[11/16 15:45:08] d2.data.build INFO: Removed 0 images with no usable annotations. 5011 images left.
[11/16 15:45:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 15:45:09] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 15:45:09] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 15:45:09] d2.data.common INFO: Serialized dataset takes 1.08 MiB
[11/16 15:45:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./data/dino_RN50_pretrain_d2_format.pkl ...
[11/16 15:45:09] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[11/16 15:45:09] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model              | Names in Checkpoint                                                                                        | Shapes                                             |
|:----------------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| backbone.res2.0.conv1.*     | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,1,1)                |
| backbone.res2.0.conv2.*     | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.0.conv3.*     | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.0.shortcut.*  | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.1.conv1.*     | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.1.conv2.*     | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.1.conv3.*     | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res2.2.conv1.*     | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| backbone.res2.2.conv2.*     | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| backbone.res2.2.conv3.*     | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| backbone.res3.0.conv1.*     | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| backbone.res3.0.conv2.*     | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.0.conv3.*     | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.0.shortcut.*  | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| backbone.res3.1.conv1.*     | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.1.conv2.*     | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.1.conv3.*     | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.2.conv1.*     | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.2.conv2.*     | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.2.conv3.*     | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res3.3.conv1.*     | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| backbone.res3.3.conv2.*     | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| backbone.res3.3.conv3.*     | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| backbone.res4.0.conv1.*     | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| backbone.res4.0.conv2.*     | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.0.conv3.*     | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.0.shortcut.*  | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.res4.1.conv1.*     | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.1.conv2.*     | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.1.conv3.*     | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.2.conv1.*     | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.2.conv2.*     | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.2.conv3.*     | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.3.conv1.*     | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.3.conv2.*     | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.3.conv3.*     | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.4.conv1.*     | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.4.conv2.*     | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.4.conv3.*     | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.res4.5.conv1.*     | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.res4.5.conv2.*     | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| backbone.res4.5.conv3.*     | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.stem.conv1.*       | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,7,7)                 |
| roi_heads.res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| roi_heads.res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| roi_heads.res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| roi_heads.res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| roi_heads.res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| roi_heads.res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
[11/16 15:45:09] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.res5.norm.{bias, running_mean, running_var, weight}[0m
[11/16 15:45:09] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mres2.0.conv1.norm.num_batches_tracked[0m
  [35mres2.0.conv2.norm.num_batches_tracked[0m
  [35mres2.0.conv3.norm.num_batches_tracked[0m
  [35mres2.0.shortcut.norm.num_batches_tracked[0m
  [35mres2.1.conv1.norm.num_batches_tracked[0m
  [35mres2.1.conv2.norm.num_batches_tracked[0m
  [35mres2.1.conv3.norm.num_batches_tracked[0m
  [35mres2.2.conv1.norm.num_batches_tracked[0m
  [35mres2.2.conv2.norm.num_batches_tracked[0m
  [35mres2.2.conv3.norm.num_batches_tracked[0m
  [35mstem.conv1.norm.num_batches_tracked[0m
[11/16 15:45:09] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 15:45:23] d2.utils.events INFO:  eta: 1:55:13  iter: 19  total_loss: 1.567  loss_cls: 0.6775  loss_box_reg: 0.09442  loss_rpn_cls: 0.5897  loss_rpn_loc: 0.2253  time: 0.6812  data_time: 0.0123  lr: 0.0038162  max_mem: 8097M
[11/16 15:45:37] d2.utils.events INFO:  eta: 1:54:26  iter: 39  total_loss: 1.24  loss_cls: 0.4094  loss_box_reg: 0.07724  loss_rpn_cls: 0.352  loss_rpn_loc: 0.3736  time: 0.6854  data_time: 0.0029  lr: 0.0078122  max_mem: 8206M
[11/16 15:45:50] d2.utils.events INFO:  eta: 1:54:39  iter: 59  total_loss: 0.8603  loss_cls: 0.191  loss_box_reg: 0.06909  loss_rpn_cls: 0.3497  loss_rpn_loc: 0.1622  time: 0.6858  data_time: 0.0028  lr: 0.011808  max_mem: 8206M
[11/16 15:46:04] d2.utils.events INFO:  eta: 1:54:46  iter: 79  total_loss: 0.7785  loss_cls: 0.1179  loss_box_reg: 0.09551  loss_rpn_cls: 0.3696  loss_rpn_loc: 0.2123  time: 0.6868  data_time: 0.0029  lr: 0.015804  max_mem: 8206M
[11/16 15:46:18] d2.utils.events INFO:  eta: 1:54:38  iter: 99  total_loss: 0.7207  loss_cls: 0.09053  loss_box_reg: 0.08502  loss_rpn_cls: 0.2945  loss_rpn_loc: 0.2033  time: 0.6905  data_time: 0.0030  lr: 0.0198  max_mem: 8206M
[11/16 15:46:32] d2.utils.events INFO:  eta: 1:54:48  iter: 119  total_loss: 0.6634  loss_cls: 0.075  loss_box_reg: 0.08451  loss_rpn_cls: 0.2649  loss_rpn_loc: 0.1959  time: 0.6936  data_time: 0.0030  lr: 0.02  max_mem: 8206M
[11/16 15:46:47] d2.utils.events INFO:  eta: 1:55:24  iter: 139  total_loss: 0.7395  loss_cls: 0.06574  loss_box_reg: 0.06755  loss_rpn_cls: 0.3475  loss_rpn_loc: 0.1629  time: 0.6949  data_time: 0.0029  lr: 0.02  max_mem: 8206M
[11/16 15:47:01] d2.utils.events INFO:  eta: 1:55:34  iter: 159  total_loss: 0.5943  loss_cls: 0.0641  loss_box_reg: 0.08422  loss_rpn_cls: 0.2396  loss_rpn_loc: 0.1432  time: 0.6973  data_time: 0.0031  lr: 0.02  max_mem: 8206M
[11/16 15:47:15] d2.utils.events INFO:  eta: 1:55:43  iter: 179  total_loss: 0.6071  loss_cls: 0.06198  loss_box_reg: 0.06476  loss_rpn_cls: 0.272  loss_rpn_loc: 0.1835  time: 0.6989  data_time: 0.0029  lr: 0.02  max_mem: 8206M
[11/16 15:47:29] d2.utils.events INFO:  eta: 1:55:35  iter: 199  total_loss: 0.6518  loss_cls: 0.0669  loss_box_reg: 0.09595  loss_rpn_cls: 0.2974  loss_rpn_loc: 0.1507  time: 0.7002  data_time: 0.0027  lr: 0.02  max_mem: 8206M
[11/16 15:47:44] d2.utils.events INFO:  eta: 1:55:26  iter: 219  total_loss: 0.7014  loss_cls: 0.06341  loss_box_reg: 0.08387  loss_rpn_cls: 0.3365  loss_rpn_loc: 0.2263  time: 0.7013  data_time: 0.0028  lr: 0.02  max_mem: 8206M
[11/16 15:47:58] d2.utils.events INFO:  eta: 1:55:12  iter: 239  total_loss: 0.6588  loss_cls: 0.06132  loss_box_reg: 0.09648  loss_rpn_cls: 0.2901  loss_rpn_loc: 0.182  time: 0.7021  data_time: 0.0027  lr: 0.02  max_mem: 8235M
[11/16 15:48:12] d2.utils.events INFO:  eta: 1:54:58  iter: 259  total_loss: 0.6283  loss_cls: 0.06572  loss_box_reg: 0.1054  loss_rpn_cls: 0.341  loss_rpn_loc: 0.1486  time: 0.7027  data_time: 0.0027  lr: 0.02  max_mem: 8235M
[11/16 15:48:26] d2.utils.events INFO:  eta: 1:54:47  iter: 279  total_loss: 0.6504  loss_cls: 0.04892  loss_box_reg: 0.08429  loss_rpn_cls: 0.3037  loss_rpn_loc: 0.2001  time: 0.7035  data_time: 0.0029  lr: 0.02  max_mem: 8235M
[11/16 15:48:41] d2.utils.events INFO:  eta: 1:54:35  iter: 299  total_loss: 0.5417  loss_cls: 0.05686  loss_box_reg: 0.1062  loss_rpn_cls: 0.2039  loss_rpn_loc: 0.1496  time: 0.7040  data_time: 0.0029  lr: 0.02  max_mem: 8235M
[11/16 15:48:55] d2.utils.events INFO:  eta: 1:54:30  iter: 319  total_loss: 0.677  loss_cls: 0.06973  loss_box_reg: 0.1041  loss_rpn_cls: 0.3642  loss_rpn_loc: 0.1266  time: 0.7051  data_time: 0.0028  lr: 0.02  max_mem: 8235M
[11/16 15:49:09] d2.utils.events INFO:  eta: 1:54:07  iter: 339  total_loss: 0.5853  loss_cls: 0.05765  loss_box_reg: 0.08455  loss_rpn_cls: 0.2636  loss_rpn_loc: 0.1338  time: 0.7050  data_time: 0.0028  lr: 0.02  max_mem: 8235M
[11/16 15:49:23] d2.utils.events INFO:  eta: 1:54:01  iter: 359  total_loss: 0.6139  loss_cls: 0.05815  loss_box_reg: 0.09798  loss_rpn_cls: 0.2556  loss_rpn_loc: 0.1686  time: 0.7056  data_time: 0.0028  lr: 0.02  max_mem: 8235M
[11/16 15:49:38] d2.utils.events INFO:  eta: 1:53:46  iter: 379  total_loss: 0.5768  loss_cls: 0.06178  loss_box_reg: 0.1191  loss_rpn_cls: 0.2246  loss_rpn_loc: 0.1458  time: 0.7057  data_time: 0.0027  lr: 0.02  max_mem: 8235M
[11/16 15:49:52] d2.utils.events INFO:  eta: 1:53:34  iter: 399  total_loss: 0.6708  loss_cls: 0.06091  loss_box_reg: 0.1008  loss_rpn_cls: 0.3332  loss_rpn_loc: 0.1596  time: 0.7063  data_time: 0.0029  lr: 0.02  max_mem: 8235M
[11/16 15:50:06] d2.utils.events INFO:  eta: 1:53:24  iter: 419  total_loss: 0.5213  loss_cls: 0.06582  loss_box_reg: 0.09312  loss_rpn_cls: 0.2338  loss_rpn_loc: 0.09301  time: 0.7067  data_time: 0.0027  lr: 0.02  max_mem: 8235M
[11/16 15:50:21] d2.utils.events INFO:  eta: 1:53:11  iter: 439  total_loss: 0.5199  loss_cls: 0.05069  loss_box_reg: 0.0853  loss_rpn_cls: 0.2254  loss_rpn_loc: 0.1381  time: 0.7073  data_time: 0.0029  lr: 0.02  max_mem: 8235M
[11/16 15:50:35] d2.utils.events INFO:  eta: 1:52:58  iter: 459  total_loss: 0.5718  loss_cls: 0.05789  loss_box_reg: 0.09741  loss_rpn_cls: 0.2671  loss_rpn_loc: 0.1313  time: 0.7078  data_time: 0.0028  lr: 0.02  max_mem: 8235M
[11/16 15:50:49] d2.utils.events INFO:  eta: 1:52:46  iter: 479  total_loss: 0.4727  loss_cls: 0.06298  loss_box_reg: 0.0976  loss_rpn_cls: 0.2329  loss_rpn_loc: 0.1002  time: 0.7083  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:51:04] d2.utils.events INFO:  eta: 1:52:40  iter: 499  total_loss: 0.5846  loss_cls: 0.05702  loss_box_reg: 0.08567  loss_rpn_cls: 0.2287  loss_rpn_loc: 0.1425  time: 0.7087  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:51:18] d2.utils.events INFO:  eta: 1:52:30  iter: 519  total_loss: 0.4754  loss_cls: 0.05354  loss_box_reg: 0.1055  loss_rpn_cls: 0.1867  loss_rpn_loc: 0.1122  time: 0.7088  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:51:32] d2.utils.events INFO:  eta: 1:52:16  iter: 539  total_loss: 0.4283  loss_cls: 0.04863  loss_box_reg: 0.09933  loss_rpn_cls: 0.1997  loss_rpn_loc: 0.08806  time: 0.7090  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:51:47] d2.utils.events INFO:  eta: 1:52:02  iter: 559  total_loss: 0.5287  loss_cls: 0.05115  loss_box_reg: 0.1124  loss_rpn_cls: 0.2459  loss_rpn_loc: 0.1023  time: 0.7093  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:52:01] d2.utils.events INFO:  eta: 1:51:49  iter: 579  total_loss: 0.5141  loss_cls: 0.05461  loss_box_reg: 0.1048  loss_rpn_cls: 0.2316  loss_rpn_loc: 0.1189  time: 0.7097  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:52:16] d2.utils.events INFO:  eta: 1:51:39  iter: 599  total_loss: 0.5023  loss_cls: 0.05384  loss_box_reg: 0.09574  loss_rpn_cls: 0.2155  loss_rpn_loc: 0.1108  time: 0.7103  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:52:30] d2.utils.events INFO:  eta: 1:51:29  iter: 619  total_loss: 0.5608  loss_cls: 0.05323  loss_box_reg: 0.09643  loss_rpn_cls: 0.2686  loss_rpn_loc: 0.1161  time: 0.7107  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:52:45] d2.utils.events INFO:  eta: 1:51:17  iter: 639  total_loss: 0.5534  loss_cls: 0.06313  loss_box_reg: 0.1056  loss_rpn_cls: 0.3035  loss_rpn_loc: 0.1071  time: 0.7109  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:52:59] d2.utils.events INFO:  eta: 1:51:04  iter: 659  total_loss: 0.527  loss_cls: 0.06092  loss_box_reg: 0.1179  loss_rpn_cls: 0.22  loss_rpn_loc: 0.09336  time: 0.7111  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:53:13] d2.utils.events INFO:  eta: 1:50:52  iter: 679  total_loss: 0.5434  loss_cls: 0.04799  loss_box_reg: 0.09923  loss_rpn_cls: 0.2404  loss_rpn_loc: 0.114  time: 0.7113  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:53:28] d2.utils.events INFO:  eta: 1:50:41  iter: 699  total_loss: 0.5103  loss_cls: 0.05278  loss_box_reg: 0.1141  loss_rpn_cls: 0.2195  loss_rpn_loc: 0.117  time: 0.7117  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:53:42] d2.utils.events INFO:  eta: 1:50:29  iter: 719  total_loss: 0.4982  loss_cls: 0.05602  loss_box_reg: 0.1015  loss_rpn_cls: 0.2527  loss_rpn_loc: 0.06021  time: 0.7119  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:53:57] d2.utils.events INFO:  eta: 1:50:15  iter: 739  total_loss: 0.5618  loss_cls: 0.04567  loss_box_reg: 0.08719  loss_rpn_cls: 0.2385  loss_rpn_loc: 0.09824  time: 0.7120  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:54:11] d2.utils.events INFO:  eta: 1:50:03  iter: 759  total_loss: 0.5962  loss_cls: 0.06182  loss_box_reg: 0.1072  loss_rpn_cls: 0.278  loss_rpn_loc: 0.115  time: 0.7124  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:54:25] d2.utils.events INFO:  eta: 1:49:48  iter: 779  total_loss: 0.4791  loss_cls: 0.0527  loss_box_reg: 0.08538  loss_rpn_cls: 0.2331  loss_rpn_loc: 0.08555  time: 0.7124  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:54:40] d2.utils.events INFO:  eta: 1:49:32  iter: 799  total_loss: 0.3981  loss_cls: 0.03298  loss_box_reg: 0.0703  loss_rpn_cls: 0.1779  loss_rpn_loc: 0.1031  time: 0.7123  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:54:54] d2.utils.events INFO:  eta: 1:49:17  iter: 819  total_loss: 0.5278  loss_cls: 0.05572  loss_box_reg: 0.1083  loss_rpn_cls: 0.2741  loss_rpn_loc: 0.1041  time: 0.7122  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:55:08] d2.utils.events INFO:  eta: 1:49:03  iter: 839  total_loss: 0.5077  loss_cls: 0.05811  loss_box_reg: 0.09984  loss_rpn_cls: 0.2677  loss_rpn_loc: 0.06033  time: 0.7122  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:55:22] d2.utils.events INFO:  eta: 1:48:45  iter: 859  total_loss: 0.5272  loss_cls: 0.04554  loss_box_reg: 0.1061  loss_rpn_cls: 0.2521  loss_rpn_loc: 0.07809  time: 0.7121  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:55:36] d2.utils.events INFO:  eta: 1:48:30  iter: 879  total_loss: 0.5055  loss_cls: 0.05576  loss_box_reg: 0.09592  loss_rpn_cls: 0.2221  loss_rpn_loc: 0.1084  time: 0.7120  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:55:51] d2.utils.events INFO:  eta: 1:48:20  iter: 899  total_loss: 0.5334  loss_cls: 0.05021  loss_box_reg: 0.09666  loss_rpn_cls: 0.2754  loss_rpn_loc: 0.1033  time: 0.7122  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:56:05] d2.utils.events INFO:  eta: 1:48:06  iter: 919  total_loss: 0.5307  loss_cls: 0.04693  loss_box_reg: 0.07563  loss_rpn_cls: 0.2654  loss_rpn_loc: 0.1141  time: 0.7124  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 15:56:20] d2.utils.events INFO:  eta: 1:47:52  iter: 939  total_loss: 0.5359  loss_cls: 0.05648  loss_box_reg: 0.08371  loss_rpn_cls: 0.2508  loss_rpn_loc: 0.09262  time: 0.7124  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 15:56:34] d2.utils.events INFO:  eta: 1:47:37  iter: 959  total_loss: 0.5356  loss_cls: 0.04621  loss_box_reg: 0.08866  loss_rpn_cls: 0.2622  loss_rpn_loc: 0.08196  time: 0.7124  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:56:48] d2.utils.events INFO:  eta: 1:47:23  iter: 979  total_loss: 0.5178  loss_cls: 0.05392  loss_box_reg: 0.09831  loss_rpn_cls: 0.2439  loss_rpn_loc: 0.1097  time: 0.7125  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:57:03] d2.utils.events INFO:  eta: 1:47:09  iter: 999  total_loss: 0.5016  loss_cls: 0.06185  loss_box_reg: 0.1085  loss_rpn_cls: 0.2008  loss_rpn_loc: 0.1052  time: 0.7126  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:57:17] d2.utils.events INFO:  eta: 1:46:57  iter: 1019  total_loss: 0.5652  loss_cls: 0.05782  loss_box_reg: 0.09812  loss_rpn_cls: 0.284  loss_rpn_loc: 0.09321  time: 0.7127  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:57:31] d2.utils.events INFO:  eta: 1:46:44  iter: 1039  total_loss: 0.5007  loss_cls: 0.05503  loss_box_reg: 0.08675  loss_rpn_cls: 0.2535  loss_rpn_loc: 0.1077  time: 0.7128  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:57:46] d2.utils.events INFO:  eta: 1:46:32  iter: 1059  total_loss: 0.449  loss_cls: 0.05054  loss_box_reg: 0.08898  loss_rpn_cls: 0.1811  loss_rpn_loc: 0.1016  time: 0.7128  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:58:00] d2.utils.events INFO:  eta: 1:46:21  iter: 1079  total_loss: 0.4929  loss_cls: 0.05781  loss_box_reg: 0.1038  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.1256  time: 0.7130  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:58:14] d2.utils.events INFO:  eta: 1:46:07  iter: 1099  total_loss: 0.4575  loss_cls: 0.04795  loss_box_reg: 0.1053  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.09659  time: 0.7129  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 15:58:29] d2.utils.events INFO:  eta: 1:45:54  iter: 1119  total_loss: 0.4132  loss_cls: 0.05629  loss_box_reg: 0.1044  loss_rpn_cls: 0.1786  loss_rpn_loc: 0.08613  time: 0.7129  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:58:43] d2.utils.events INFO:  eta: 1:45:40  iter: 1139  total_loss: 0.4764  loss_cls: 0.05099  loss_box_reg: 0.07959  loss_rpn_cls: 0.2411  loss_rpn_loc: 0.06231  time: 0.7129  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 15:58:57] d2.utils.events INFO:  eta: 1:45:26  iter: 1159  total_loss: 0.4864  loss_cls: 0.04715  loss_box_reg: 0.08161  loss_rpn_cls: 0.2201  loss_rpn_loc: 0.1085  time: 0.7130  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:59:12] d2.utils.events INFO:  eta: 1:45:13  iter: 1179  total_loss: 0.4822  loss_cls: 0.0346  loss_box_reg: 0.07182  loss_rpn_cls: 0.2117  loss_rpn_loc: 0.1523  time: 0.7131  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:59:26] d2.utils.events INFO:  eta: 1:44:59  iter: 1199  total_loss: 0.4685  loss_cls: 0.0455  loss_box_reg: 0.09145  loss_rpn_cls: 0.1871  loss_rpn_loc: 0.1381  time: 0.7133  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 15:59:40] d2.utils.events INFO:  eta: 1:44:45  iter: 1219  total_loss: 0.4039  loss_cls: 0.05251  loss_box_reg: 0.08862  loss_rpn_cls: 0.175  loss_rpn_loc: 0.07931  time: 0.7133  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 15:59:55] d2.utils.events INFO:  eta: 1:44:33  iter: 1239  total_loss: 0.4997  loss_cls: 0.05028  loss_box_reg: 0.09218  loss_rpn_cls: 0.23  loss_rpn_loc: 0.1166  time: 0.7135  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:00:09] d2.utils.events INFO:  eta: 1:44:20  iter: 1259  total_loss: 0.4774  loss_cls: 0.05173  loss_box_reg: 0.1069  loss_rpn_cls: 0.216  loss_rpn_loc: 0.09365  time: 0.7136  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:00:23] d2.utils.events INFO:  eta: 1:44:05  iter: 1279  total_loss: 0.397  loss_cls: 0.05358  loss_box_reg: 0.08185  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.07383  time: 0.7135  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:00:38] d2.utils.events INFO:  eta: 1:43:53  iter: 1299  total_loss: 0.4904  loss_cls: 0.05182  loss_box_reg: 0.09257  loss_rpn_cls: 0.219  loss_rpn_loc: 0.09749  time: 0.7136  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:00:52] d2.utils.events INFO:  eta: 1:43:39  iter: 1319  total_loss: 0.4417  loss_cls: 0.06146  loss_box_reg: 0.09638  loss_rpn_cls: 0.1961  loss_rpn_loc: 0.07555  time: 0.7137  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:01:07] d2.utils.events INFO:  eta: 1:43:28  iter: 1339  total_loss: 0.4649  loss_cls: 0.0591  loss_box_reg: 0.1093  loss_rpn_cls: 0.1986  loss_rpn_loc: 0.09327  time: 0.7137  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:01:21] d2.utils.events INFO:  eta: 1:43:11  iter: 1359  total_loss: 0.4604  loss_cls: 0.05844  loss_box_reg: 0.1074  loss_rpn_cls: 0.2219  loss_rpn_loc: 0.08936  time: 0.7137  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:01:35] d2.utils.events INFO:  eta: 1:42:58  iter: 1379  total_loss: 0.481  loss_cls: 0.06452  loss_box_reg: 0.1136  loss_rpn_cls: 0.2024  loss_rpn_loc: 0.06319  time: 0.7137  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:01:49] d2.utils.events INFO:  eta: 1:42:41  iter: 1399  total_loss: 0.4088  loss_cls: 0.04442  loss_box_reg: 0.08277  loss_rpn_cls: 0.185  loss_rpn_loc: 0.07365  time: 0.7136  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:02:04] d2.utils.events INFO:  eta: 1:42:30  iter: 1419  total_loss: 0.4164  loss_cls: 0.05425  loss_box_reg: 0.1131  loss_rpn_cls: 0.1743  loss_rpn_loc: 0.07635  time: 0.7137  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:02:18] d2.utils.events INFO:  eta: 1:42:15  iter: 1439  total_loss: 0.4805  loss_cls: 0.05449  loss_box_reg: 0.09909  loss_rpn_cls: 0.2161  loss_rpn_loc: 0.07575  time: 0.7138  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:02:32] d2.utils.events INFO:  eta: 1:42:01  iter: 1459  total_loss: 0.469  loss_cls: 0.05533  loss_box_reg: 0.0873  loss_rpn_cls: 0.2054  loss_rpn_loc: 0.09481  time: 0.7138  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:02:47] d2.utils.events INFO:  eta: 1:41:45  iter: 1479  total_loss: 0.5089  loss_cls: 0.06312  loss_box_reg: 0.09546  loss_rpn_cls: 0.2286  loss_rpn_loc: 0.07984  time: 0.7139  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:03:01] d2.utils.events INFO:  eta: 1:41:31  iter: 1499  total_loss: 0.4074  loss_cls: 0.05312  loss_box_reg: 0.07983  loss_rpn_cls: 0.1795  loss_rpn_loc: 0.08159  time: 0.7140  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:03:16] d2.utils.events INFO:  eta: 1:41:16  iter: 1519  total_loss: 0.4322  loss_cls: 0.03887  loss_box_reg: 0.08236  loss_rpn_cls: 0.1712  loss_rpn_loc: 0.1253  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:03:30] d2.utils.events INFO:  eta: 1:40:59  iter: 1539  total_loss: 0.4668  loss_cls: 0.06101  loss_box_reg: 0.1026  loss_rpn_cls: 0.1921  loss_rpn_loc: 0.08737  time: 0.7140  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:03:44] d2.utils.events INFO:  eta: 1:40:48  iter: 1559  total_loss: 0.5137  loss_cls: 0.06015  loss_box_reg: 0.104  loss_rpn_cls: 0.2124  loss_rpn_loc: 0.1188  time: 0.7140  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:03:59] d2.utils.events INFO:  eta: 1:40:31  iter: 1579  total_loss: 0.4734  loss_cls: 0.0547  loss_box_reg: 0.09475  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.08448  time: 0.7141  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:04:13] d2.utils.events INFO:  eta: 1:40:13  iter: 1599  total_loss: 0.4657  loss_cls: 0.05222  loss_box_reg: 0.09577  loss_rpn_cls: 0.2033  loss_rpn_loc: 0.06728  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:04:27] d2.utils.events INFO:  eta: 1:39:58  iter: 1619  total_loss: 0.4318  loss_cls: 0.04854  loss_box_reg: 0.08813  loss_rpn_cls: 0.1704  loss_rpn_loc: 0.1112  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:04:42] d2.utils.events INFO:  eta: 1:39:44  iter: 1639  total_loss: 0.4033  loss_cls: 0.04452  loss_box_reg: 0.09685  loss_rpn_cls: 0.1624  loss_rpn_loc: 0.08097  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:04:56] d2.utils.events INFO:  eta: 1:39:29  iter: 1659  total_loss: 0.4431  loss_cls: 0.06718  loss_box_reg: 0.1065  loss_rpn_cls: 0.1735  loss_rpn_loc: 0.06657  time: 0.7141  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:05:10] d2.utils.events INFO:  eta: 1:39:13  iter: 1679  total_loss: 0.3543  loss_cls: 0.04687  loss_box_reg: 0.1003  loss_rpn_cls: 0.1339  loss_rpn_loc: 0.06804  time: 0.7141  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:05:25] d2.utils.events INFO:  eta: 1:38:59  iter: 1699  total_loss: 0.3925  loss_cls: 0.04266  loss_box_reg: 0.08505  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.1099  time: 0.7142  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:05:39] d2.utils.events INFO:  eta: 1:38:45  iter: 1719  total_loss: 0.3939  loss_cls: 0.0521  loss_box_reg: 0.09273  loss_rpn_cls: 0.1506  loss_rpn_loc: 0.08388  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:05:53] d2.utils.events INFO:  eta: 1:38:30  iter: 1739  total_loss: 0.4571  loss_cls: 0.05262  loss_box_reg: 0.09268  loss_rpn_cls: 0.1686  loss_rpn_loc: 0.09415  time: 0.7141  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 16:06:07] d2.utils.events INFO:  eta: 1:38:14  iter: 1759  total_loss: 0.4373  loss_cls: 0.0554  loss_box_reg: 0.0941  loss_rpn_cls: 0.2217  loss_rpn_loc: 0.06536  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:06:22] d2.utils.events INFO:  eta: 1:37:59  iter: 1779  total_loss: 0.4204  loss_cls: 0.05006  loss_box_reg: 0.1098  loss_rpn_cls: 0.1547  loss_rpn_loc: 0.07275  time: 0.7140  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:06:36] d2.utils.events INFO:  eta: 1:37:44  iter: 1799  total_loss: 0.4817  loss_cls: 0.04563  loss_box_reg: 0.08239  loss_rpn_cls: 0.2123  loss_rpn_loc: 0.08846  time: 0.7140  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:06:50] d2.utils.events INFO:  eta: 1:37:28  iter: 1819  total_loss: 0.3731  loss_cls: 0.04491  loss_box_reg: 0.093  loss_rpn_cls: 0.1756  loss_rpn_loc: 0.05999  time: 0.7139  data_time: 0.0033  lr: 0.02  max_mem: 8272M
[11/16 16:07:04] d2.utils.events INFO:  eta: 1:37:14  iter: 1839  total_loss: 0.4483  loss_cls: 0.05084  loss_box_reg: 0.09441  loss_rpn_cls: 0.2093  loss_rpn_loc: 0.08316  time: 0.7139  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 16:07:18] d2.utils.events INFO:  eta: 1:36:59  iter: 1859  total_loss: 0.4544  loss_cls: 0.05841  loss_box_reg: 0.08519  loss_rpn_cls: 0.255  loss_rpn_loc: 0.09207  time: 0.7139  data_time: 0.0033  lr: 0.02  max_mem: 8272M
[11/16 16:07:33] d2.utils.events INFO:  eta: 1:36:46  iter: 1879  total_loss: 0.4972  loss_cls: 0.05858  loss_box_reg: 0.1113  loss_rpn_cls: 0.2107  loss_rpn_loc: 0.06886  time: 0.7139  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 16:07:47] d2.utils.events INFO:  eta: 1:36:31  iter: 1899  total_loss: 0.544  loss_cls: 0.06984  loss_box_reg: 0.106  loss_rpn_cls: 0.2673  loss_rpn_loc: 0.1  time: 0.7139  data_time: 0.0032  lr: 0.02  max_mem: 8272M
[11/16 16:08:01] d2.utils.events INFO:  eta: 1:36:15  iter: 1919  total_loss: 0.5093  loss_cls: 0.05826  loss_box_reg: 0.1039  loss_rpn_cls: 0.2127  loss_rpn_loc: 0.1032  time: 0.7139  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 16:08:16] d2.utils.events INFO:  eta: 1:35:59  iter: 1939  total_loss: 0.4529  loss_cls: 0.06179  loss_box_reg: 0.1041  loss_rpn_cls: 0.2171  loss_rpn_loc: 0.07722  time: 0.7138  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:08:30] d2.utils.events INFO:  eta: 1:35:48  iter: 1959  total_loss: 0.4402  loss_cls: 0.06616  loss_box_reg: 0.1049  loss_rpn_cls: 0.1698  loss_rpn_loc: 0.1074  time: 0.7139  data_time: 0.0032  lr: 0.02  max_mem: 8272M
[11/16 16:08:44] d2.utils.events INFO:  eta: 1:35:33  iter: 1979  total_loss: 0.467  loss_cls: 0.04858  loss_box_reg: 0.09032  loss_rpn_cls: 0.1857  loss_rpn_loc: 0.1041  time: 0.7139  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:08:58] d2.utils.events INFO:  eta: 1:35:18  iter: 1999  total_loss: 0.4865  loss_cls: 0.05703  loss_box_reg: 0.1034  loss_rpn_cls: 0.1991  loss_rpn_loc: 0.09197  time: 0.7138  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:09:13] d2.utils.events INFO:  eta: 1:35:03  iter: 2019  total_loss: 0.4289  loss_cls: 0.05062  loss_box_reg: 0.09539  loss_rpn_cls: 0.1843  loss_rpn_loc: 0.08126  time: 0.7138  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:09:27] d2.utils.events INFO:  eta: 1:34:48  iter: 2039  total_loss: 0.4328  loss_cls: 0.05625  loss_box_reg: 0.09838  loss_rpn_cls: 0.1915  loss_rpn_loc: 0.08395  time: 0.7138  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:09:41] d2.utils.events INFO:  eta: 1:34:35  iter: 2059  total_loss: 0.3596  loss_cls: 0.05942  loss_box_reg: 0.09012  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.0736  time: 0.7139  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:09:56] d2.utils.events INFO:  eta: 1:34:23  iter: 2079  total_loss: 0.4406  loss_cls: 0.05439  loss_box_reg: 0.1048  loss_rpn_cls: 0.1783  loss_rpn_loc: 0.1181  time: 0.7140  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:10:10] d2.utils.events INFO:  eta: 1:34:09  iter: 2099  total_loss: 0.4278  loss_cls: 0.05908  loss_box_reg: 0.09592  loss_rpn_cls: 0.194  loss_rpn_loc: 0.07852  time: 0.7140  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:10:25] d2.utils.events INFO:  eta: 1:33:57  iter: 2119  total_loss: 0.4715  loss_cls: 0.05591  loss_box_reg: 0.09703  loss_rpn_cls: 0.1914  loss_rpn_loc: 0.09448  time: 0.7141  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:10:39] d2.utils.events INFO:  eta: 1:33:43  iter: 2139  total_loss: 0.4401  loss_cls: 0.05987  loss_box_reg: 0.1103  loss_rpn_cls: 0.1817  loss_rpn_loc: 0.05384  time: 0.7142  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:10:54] d2.utils.events INFO:  eta: 1:33:29  iter: 2159  total_loss: 0.4172  loss_cls: 0.05563  loss_box_reg: 0.1097  loss_rpn_cls: 0.1665  loss_rpn_loc: 0.07356  time: 0.7142  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:11:08] d2.utils.events INFO:  eta: 1:33:15  iter: 2179  total_loss: 0.435  loss_cls: 0.0541  loss_box_reg: 0.09768  loss_rpn_cls: 0.168  loss_rpn_loc: 0.07498  time: 0.7143  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:11:22] d2.utils.events INFO:  eta: 1:33:00  iter: 2199  total_loss: 0.4459  loss_cls: 0.05062  loss_box_reg: 0.08229  loss_rpn_cls: 0.1943  loss_rpn_loc: 0.07779  time: 0.7143  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:11:37] d2.utils.events INFO:  eta: 1:32:45  iter: 2219  total_loss: 0.4521  loss_cls: 0.04453  loss_box_reg: 0.07443  loss_rpn_cls: 0.1979  loss_rpn_loc: 0.1183  time: 0.7143  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:11:51] d2.utils.events INFO:  eta: 1:32:27  iter: 2239  total_loss: 0.4284  loss_cls: 0.0369  loss_box_reg: 0.08252  loss_rpn_cls: 0.1668  loss_rpn_loc: 0.1107  time: 0.7143  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:12:05] d2.utils.events INFO:  eta: 1:32:14  iter: 2259  total_loss: 0.4064  loss_cls: 0.04876  loss_box_reg: 0.09183  loss_rpn_cls: 0.1495  loss_rpn_loc: 0.08949  time: 0.7144  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:12:20] d2.utils.events INFO:  eta: 1:32:02  iter: 2279  total_loss: 0.4091  loss_cls: 0.04298  loss_box_reg: 0.08058  loss_rpn_cls: 0.1632  loss_rpn_loc: 0.09842  time: 0.7144  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:12:34] d2.utils.events INFO:  eta: 1:31:46  iter: 2299  total_loss: 0.3858  loss_cls: 0.04504  loss_box_reg: 0.09007  loss_rpn_cls: 0.1459  loss_rpn_loc: 0.0749  time: 0.7144  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:12:48] d2.utils.events INFO:  eta: 1:31:30  iter: 2319  total_loss: 0.443  loss_cls: 0.05654  loss_box_reg: 0.1027  loss_rpn_cls: 0.1508  loss_rpn_loc: 0.08038  time: 0.7144  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:13:03] d2.utils.events INFO:  eta: 1:31:15  iter: 2339  total_loss: 0.4113  loss_cls: 0.04636  loss_box_reg: 0.08963  loss_rpn_cls: 0.1809  loss_rpn_loc: 0.07096  time: 0.7145  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:13:17] d2.utils.events INFO:  eta: 1:31:02  iter: 2359  total_loss: 0.3775  loss_cls: 0.05565  loss_box_reg: 0.08762  loss_rpn_cls: 0.1592  loss_rpn_loc: 0.05873  time: 0.7145  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:13:32] d2.utils.events INFO:  eta: 1:30:49  iter: 2379  total_loss: 0.4469  loss_cls: 0.04435  loss_box_reg: 0.08342  loss_rpn_cls: 0.2102  loss_rpn_loc: 0.06707  time: 0.7145  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:13:46] d2.utils.events INFO:  eta: 1:30:34  iter: 2399  total_loss: 0.4201  loss_cls: 0.05653  loss_box_reg: 0.09555  loss_rpn_cls: 0.1746  loss_rpn_loc: 0.07578  time: 0.7145  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:14:00] d2.utils.events INFO:  eta: 1:30:20  iter: 2419  total_loss: 0.4304  loss_cls: 0.06126  loss_box_reg: 0.08349  loss_rpn_cls: 0.209  loss_rpn_loc: 0.06131  time: 0.7145  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:14:15] d2.utils.events INFO:  eta: 1:30:04  iter: 2439  total_loss: 0.4284  loss_cls: 0.04895  loss_box_reg: 0.0935  loss_rpn_cls: 0.1997  loss_rpn_loc: 0.06757  time: 0.7145  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:14:29] d2.utils.events INFO:  eta: 1:29:47  iter: 2459  total_loss: 0.4158  loss_cls: 0.05059  loss_box_reg: 0.09503  loss_rpn_cls: 0.1802  loss_rpn_loc: 0.08392  time: 0.7145  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:14:43] d2.utils.events INFO:  eta: 1:29:33  iter: 2479  total_loss: 0.4014  loss_cls: 0.05771  loss_box_reg: 0.09788  loss_rpn_cls: 0.1703  loss_rpn_loc: 0.07057  time: 0.7145  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:14:57] d2.utils.events INFO:  eta: 1:29:17  iter: 2499  total_loss: 0.3926  loss_cls: 0.04837  loss_box_reg: 0.09418  loss_rpn_cls: 0.1729  loss_rpn_loc: 0.06986  time: 0.7145  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:15:12] d2.utils.events INFO:  eta: 1:29:03  iter: 2519  total_loss: 0.402  loss_cls: 0.05578  loss_box_reg: 0.1024  loss_rpn_cls: 0.1716  loss_rpn_loc: 0.07902  time: 0.7145  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:15:26] d2.utils.events INFO:  eta: 1:28:49  iter: 2539  total_loss: 0.3519  loss_cls: 0.04192  loss_box_reg: 0.0866  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.05519  time: 0.7144  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:15:40] d2.utils.events INFO:  eta: 1:28:34  iter: 2559  total_loss: 0.4388  loss_cls: 0.04848  loss_box_reg: 0.09696  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.1044  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:15:55] d2.utils.events INFO:  eta: 1:28:20  iter: 2579  total_loss: 0.4668  loss_cls: 0.06826  loss_box_reg: 0.08946  loss_rpn_cls: 0.1971  loss_rpn_loc: 0.08596  time: 0.7145  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:16:09] d2.utils.events INFO:  eta: 1:28:06  iter: 2599  total_loss: 0.3989  loss_cls: 0.04511  loss_box_reg: 0.08208  loss_rpn_cls: 0.175  loss_rpn_loc: 0.06855  time: 0.7145  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:16:23] d2.utils.events INFO:  eta: 1:27:50  iter: 2619  total_loss: 0.3461  loss_cls: 0.03456  loss_box_reg: 0.0826  loss_rpn_cls: 0.1427  loss_rpn_loc: 0.07338  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:16:37] d2.utils.events INFO:  eta: 1:27:36  iter: 2639  total_loss: 0.4085  loss_cls: 0.04229  loss_box_reg: 0.08979  loss_rpn_cls: 0.1347  loss_rpn_loc: 0.09654  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:16:52] d2.utils.events INFO:  eta: 1:27:20  iter: 2659  total_loss: 0.3851  loss_cls: 0.05304  loss_box_reg: 0.09121  loss_rpn_cls: 0.1361  loss_rpn_loc: 0.06422  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:17:06] d2.utils.events INFO:  eta: 1:27:08  iter: 2679  total_loss: 0.3809  loss_cls: 0.05376  loss_box_reg: 0.08347  loss_rpn_cls: 0.1438  loss_rpn_loc: 0.0768  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:17:20] d2.utils.events INFO:  eta: 1:26:52  iter: 2699  total_loss: 0.4234  loss_cls: 0.05081  loss_box_reg: 0.08547  loss_rpn_cls: 0.1922  loss_rpn_loc: 0.06384  time: 0.7144  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:17:35] d2.utils.events INFO:  eta: 1:26:37  iter: 2719  total_loss: 0.4039  loss_cls: 0.04637  loss_box_reg: 0.09017  loss_rpn_cls: 0.169  loss_rpn_loc: 0.07637  time: 0.7144  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:17:49] d2.utils.events INFO:  eta: 1:26:23  iter: 2739  total_loss: 0.4194  loss_cls: 0.04963  loss_box_reg: 0.08244  loss_rpn_cls: 0.1871  loss_rpn_loc: 0.0769  time: 0.7145  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:18:03] d2.utils.events INFO:  eta: 1:26:08  iter: 2759  total_loss: 0.4041  loss_cls: 0.04883  loss_box_reg: 0.0811  loss_rpn_cls: 0.1473  loss_rpn_loc: 0.09769  time: 0.7144  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:18:18] d2.utils.events INFO:  eta: 1:25:55  iter: 2779  total_loss: 0.4264  loss_cls: 0.05273  loss_box_reg: 0.09329  loss_rpn_cls: 0.149  loss_rpn_loc: 0.08046  time: 0.7145  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:18:32] d2.utils.events INFO:  eta: 1:25:43  iter: 2799  total_loss: 0.3911  loss_cls: 0.05826  loss_box_reg: 0.1118  loss_rpn_cls: 0.1471  loss_rpn_loc: 0.09213  time: 0.7145  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:18:47] d2.utils.events INFO:  eta: 1:25:30  iter: 2819  total_loss: 0.3809  loss_cls: 0.05752  loss_box_reg: 0.09469  loss_rpn_cls: 0.1481  loss_rpn_loc: 0.07731  time: 0.7146  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:19:01] d2.utils.events INFO:  eta: 1:25:16  iter: 2839  total_loss: 0.3925  loss_cls: 0.05134  loss_box_reg: 0.1053  loss_rpn_cls: 0.1473  loss_rpn_loc: 0.08258  time: 0.7146  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:19:15] d2.utils.events INFO:  eta: 1:25:02  iter: 2859  total_loss: 0.4434  loss_cls: 0.04448  loss_box_reg: 0.08506  loss_rpn_cls: 0.1486  loss_rpn_loc: 0.133  time: 0.7146  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:19:29] d2.utils.events INFO:  eta: 1:24:46  iter: 2879  total_loss: 0.4194  loss_cls: 0.04481  loss_box_reg: 0.0855  loss_rpn_cls: 0.1729  loss_rpn_loc: 0.08251  time: 0.7145  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:19:44] d2.utils.events INFO:  eta: 1:24:33  iter: 2899  total_loss: 0.4272  loss_cls: 0.05341  loss_box_reg: 0.0962  loss_rpn_cls: 0.1625  loss_rpn_loc: 0.09319  time: 0.7146  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:19:58] d2.utils.events INFO:  eta: 1:24:18  iter: 2919  total_loss: 0.3625  loss_cls: 0.0492  loss_box_reg: 0.09481  loss_rpn_cls: 0.1586  loss_rpn_loc: 0.07847  time: 0.7146  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:20:13] d2.utils.events INFO:  eta: 1:24:06  iter: 2939  total_loss: 0.3798  loss_cls: 0.04765  loss_box_reg: 0.08373  loss_rpn_cls: 0.1534  loss_rpn_loc: 0.08634  time: 0.7146  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:20:27] d2.utils.events INFO:  eta: 1:23:50  iter: 2959  total_loss: 0.4669  loss_cls: 0.0517  loss_box_reg: 0.08605  loss_rpn_cls: 0.1791  loss_rpn_loc: 0.1217  time: 0.7147  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:20:42] d2.utils.events INFO:  eta: 1:23:37  iter: 2979  total_loss: 0.4199  loss_cls: 0.04974  loss_box_reg: 0.08864  loss_rpn_cls: 0.1784  loss_rpn_loc: 0.08253  time: 0.7147  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:20:56] d2.utils.events INFO:  eta: 1:23:29  iter: 2999  total_loss: 0.3527  loss_cls: 0.04734  loss_box_reg: 0.08228  loss_rpn_cls: 0.1518  loss_rpn_loc: 0.07097  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:21:10] d2.utils.events INFO:  eta: 1:23:13  iter: 3019  total_loss: 0.365  loss_cls: 0.04255  loss_box_reg: 0.08288  loss_rpn_cls: 0.1573  loss_rpn_loc: 0.08824  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:21:25] d2.utils.events INFO:  eta: 1:23:00  iter: 3039  total_loss: 0.3905  loss_cls: 0.05217  loss_box_reg: 0.09722  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.08782  time: 0.7148  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:21:39] d2.utils.events INFO:  eta: 1:22:44  iter: 3059  total_loss: 0.4427  loss_cls: 0.0548  loss_box_reg: 0.08155  loss_rpn_cls: 0.1829  loss_rpn_loc: 0.09563  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:21:53] d2.utils.events INFO:  eta: 1:22:26  iter: 3079  total_loss: 0.4533  loss_cls: 0.04387  loss_box_reg: 0.08239  loss_rpn_cls: 0.1621  loss_rpn_loc: 0.1089  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:22:08] d2.utils.events INFO:  eta: 1:22:12  iter: 3099  total_loss: 0.3733  loss_cls: 0.04909  loss_box_reg: 0.09058  loss_rpn_cls: 0.1689  loss_rpn_loc: 0.08498  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:22:22] d2.utils.events INFO:  eta: 1:21:57  iter: 3119  total_loss: 0.449  loss_cls: 0.05555  loss_box_reg: 0.08692  loss_rpn_cls: 0.1912  loss_rpn_loc: 0.09191  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:22:37] d2.utils.events INFO:  eta: 1:21:42  iter: 3139  total_loss: 0.4966  loss_cls: 0.05574  loss_box_reg: 0.09076  loss_rpn_cls: 0.1794  loss_rpn_loc: 0.1452  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:22:51] d2.utils.events INFO:  eta: 1:21:28  iter: 3159  total_loss: 0.3991  loss_cls: 0.05819  loss_box_reg: 0.08227  loss_rpn_cls: 0.152  loss_rpn_loc: 0.08389  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:23:05] d2.utils.events INFO:  eta: 1:21:13  iter: 3179  total_loss: 0.4654  loss_cls: 0.05605  loss_box_reg: 0.09541  loss_rpn_cls: 0.1795  loss_rpn_loc: 0.1322  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:23:20] d2.utils.events INFO:  eta: 1:20:59  iter: 3199  total_loss: 0.4455  loss_cls: 0.06118  loss_box_reg: 0.1003  loss_rpn_cls: 0.156  loss_rpn_loc: 0.09869  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:23:34] d2.utils.events INFO:  eta: 1:20:44  iter: 3219  total_loss: 0.4567  loss_cls: 0.0535  loss_box_reg: 0.09994  loss_rpn_cls: 0.1778  loss_rpn_loc: 0.09713  time: 0.7150  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:23:48] d2.utils.events INFO:  eta: 1:20:32  iter: 3239  total_loss: 0.4131  loss_cls: 0.04975  loss_box_reg: 0.08587  loss_rpn_cls: 0.185  loss_rpn_loc: 0.0676  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:24:03] d2.utils.events INFO:  eta: 1:20:16  iter: 3259  total_loss: 0.4085  loss_cls: 0.05722  loss_box_reg: 0.08708  loss_rpn_cls: 0.1736  loss_rpn_loc: 0.0901  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:24:17] d2.utils.events INFO:  eta: 1:20:01  iter: 3279  total_loss: 0.4252  loss_cls: 0.05519  loss_box_reg: 0.08867  loss_rpn_cls: 0.1909  loss_rpn_loc: 0.06557  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:24:32] d2.utils.events INFO:  eta: 1:19:47  iter: 3299  total_loss: 0.3785  loss_cls: 0.0437  loss_box_reg: 0.07716  loss_rpn_cls: 0.1592  loss_rpn_loc: 0.07231  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:24:46] d2.utils.events INFO:  eta: 1:19:32  iter: 3319  total_loss: 0.4049  loss_cls: 0.04684  loss_box_reg: 0.08553  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.0841  time: 0.7150  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:25:00] d2.utils.events INFO:  eta: 1:19:18  iter: 3339  total_loss: 0.3972  loss_cls: 0.05454  loss_box_reg: 0.1004  loss_rpn_cls: 0.1531  loss_rpn_loc: 0.06001  time: 0.7150  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:25:15] d2.utils.events INFO:  eta: 1:19:04  iter: 3359  total_loss: 0.4527  loss_cls: 0.0612  loss_box_reg: 0.1145  loss_rpn_cls: 0.1544  loss_rpn_loc: 0.09331  time: 0.7151  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:25:29] d2.utils.events INFO:  eta: 1:18:50  iter: 3379  total_loss: 0.4558  loss_cls: 0.05726  loss_box_reg: 0.09624  loss_rpn_cls: 0.191  loss_rpn_loc: 0.06523  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:25:43] d2.utils.events INFO:  eta: 1:18:35  iter: 3399  total_loss: 0.4075  loss_cls: 0.0422  loss_box_reg: 0.08251  loss_rpn_cls: 0.1791  loss_rpn_loc: 0.07632  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:25:58] d2.utils.events INFO:  eta: 1:18:21  iter: 3419  total_loss: 0.4068  loss_cls: 0.0459  loss_box_reg: 0.08249  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.1088  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:26:12] d2.utils.events INFO:  eta: 1:18:07  iter: 3439  total_loss: 0.4011  loss_cls: 0.05598  loss_box_reg: 0.08556  loss_rpn_cls: 0.1724  loss_rpn_loc: 0.07546  time: 0.7151  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:26:26] d2.utils.events INFO:  eta: 1:17:53  iter: 3459  total_loss: 0.3268  loss_cls: 0.04281  loss_box_reg: 0.08012  loss_rpn_cls: 0.138  loss_rpn_loc: 0.07132  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:26:41] d2.utils.events INFO:  eta: 1:17:38  iter: 3479  total_loss: 0.3985  loss_cls: 0.04894  loss_box_reg: 0.08376  loss_rpn_cls: 0.1746  loss_rpn_loc: 0.1  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:26:55] d2.utils.events INFO:  eta: 1:17:26  iter: 3499  total_loss: 0.4786  loss_cls: 0.05672  loss_box_reg: 0.09662  loss_rpn_cls: 0.2044  loss_rpn_loc: 0.07897  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:27:09] d2.utils.events INFO:  eta: 1:17:10  iter: 3519  total_loss: 0.3761  loss_cls: 0.05002  loss_box_reg: 0.07663  loss_rpn_cls: 0.1571  loss_rpn_loc: 0.06762  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:27:24] d2.utils.events INFO:  eta: 1:16:58  iter: 3539  total_loss: 0.3584  loss_cls: 0.04574  loss_box_reg: 0.07377  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.09575  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:27:38] d2.utils.events INFO:  eta: 1:16:43  iter: 3559  total_loss: 0.352  loss_cls: 0.05301  loss_box_reg: 0.07927  loss_rpn_cls: 0.1615  loss_rpn_loc: 0.05844  time: 0.7150  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:27:52] d2.utils.events INFO:  eta: 1:16:27  iter: 3579  total_loss: 0.333  loss_cls: 0.04909  loss_box_reg: 0.09122  loss_rpn_cls: 0.1355  loss_rpn_loc: 0.05379  time: 0.7150  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:28:06] d2.utils.events INFO:  eta: 1:16:11  iter: 3599  total_loss: 0.4163  loss_cls: 0.05034  loss_box_reg: 0.1034  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.09677  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:28:20] d2.utils.events INFO:  eta: 1:15:58  iter: 3619  total_loss: 0.4185  loss_cls: 0.06055  loss_box_reg: 0.08497  loss_rpn_cls: 0.1774  loss_rpn_loc: 0.05412  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:28:35] d2.utils.events INFO:  eta: 1:15:43  iter: 3639  total_loss: 0.3502  loss_cls: 0.0491  loss_box_reg: 0.1009  loss_rpn_cls: 0.159  loss_rpn_loc: 0.0715  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:28:49] d2.utils.events INFO:  eta: 1:15:29  iter: 3659  total_loss: 0.3924  loss_cls: 0.0413  loss_box_reg: 0.09475  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.07514  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:29:03] d2.utils.events INFO:  eta: 1:15:15  iter: 3679  total_loss: 0.3736  loss_cls: 0.04633  loss_box_reg: 0.09049  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.08265  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:29:17] d2.utils.events INFO:  eta: 1:15:01  iter: 3699  total_loss: 0.3447  loss_cls: 0.04765  loss_box_reg: 0.1008  loss_rpn_cls: 0.1456  loss_rpn_loc: 0.06571  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:29:32] d2.utils.events INFO:  eta: 1:14:46  iter: 3719  total_loss: 0.3465  loss_cls: 0.03885  loss_box_reg: 0.08478  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.06446  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:29:46] d2.utils.events INFO:  eta: 1:14:31  iter: 3739  total_loss: 0.3662  loss_cls: 0.04063  loss_box_reg: 0.08373  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.06708  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:30:00] d2.utils.events INFO:  eta: 1:14:18  iter: 3759  total_loss: 0.3501  loss_cls: 0.04062  loss_box_reg: 0.08128  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.1096  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:30:15] d2.utils.events INFO:  eta: 1:14:04  iter: 3779  total_loss: 0.3779  loss_cls: 0.04861  loss_box_reg: 0.08942  loss_rpn_cls: 0.1597  loss_rpn_loc: 0.07519  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:30:29] d2.utils.events INFO:  eta: 1:13:49  iter: 3799  total_loss: 0.428  loss_cls: 0.04799  loss_box_reg: 0.09491  loss_rpn_cls: 0.1504  loss_rpn_loc: 0.1109  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:30:43] d2.utils.events INFO:  eta: 1:13:33  iter: 3819  total_loss: 0.3524  loss_cls: 0.05194  loss_box_reg: 0.09025  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.07162  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:30:58] d2.utils.events INFO:  eta: 1:13:19  iter: 3839  total_loss: 0.4564  loss_cls: 0.06129  loss_box_reg: 0.09986  loss_rpn_cls: 0.1973  loss_rpn_loc: 0.06971  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:31:12] d2.utils.events INFO:  eta: 1:13:04  iter: 3859  total_loss: 0.3849  loss_cls: 0.05321  loss_box_reg: 0.08244  loss_rpn_cls: 0.1773  loss_rpn_loc: 0.08376  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:31:26] d2.utils.events INFO:  eta: 1:12:49  iter: 3879  total_loss: 0.3567  loss_cls: 0.03932  loss_box_reg: 0.08602  loss_rpn_cls: 0.1829  loss_rpn_loc: 0.05239  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:31:40] d2.utils.events INFO:  eta: 1:12:33  iter: 3899  total_loss: 0.403  loss_cls: 0.04923  loss_box_reg: 0.1137  loss_rpn_cls: 0.1326  loss_rpn_loc: 0.07979  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:31:55] d2.utils.events INFO:  eta: 1:12:20  iter: 3919  total_loss: 0.3992  loss_cls: 0.053  loss_box_reg: 0.09445  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.07841  time: 0.7148  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:32:09] d2.utils.events INFO:  eta: 1:12:03  iter: 3939  total_loss: 0.3497  loss_cls: 0.04845  loss_box_reg: 0.1083  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.07364  time: 0.7148  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:32:23] d2.utils.events INFO:  eta: 1:11:48  iter: 3959  total_loss: 0.3878  loss_cls: 0.03895  loss_box_reg: 0.09315  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.07227  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:32:38] d2.utils.events INFO:  eta: 1:11:33  iter: 3979  total_loss: 0.3926  loss_cls: 0.04489  loss_box_reg: 0.08484  loss_rpn_cls: 0.1407  loss_rpn_loc: 0.09654  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:32:52] d2.utils.events INFO:  eta: 1:11:19  iter: 3999  total_loss: 0.404  loss_cls: 0.06025  loss_box_reg: 0.08325  loss_rpn_cls: 0.1705  loss_rpn_loc: 0.05973  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:33:06] d2.utils.events INFO:  eta: 1:11:05  iter: 4019  total_loss: 0.3635  loss_cls: 0.0509  loss_box_reg: 0.1029  loss_rpn_cls: 0.136  loss_rpn_loc: 0.0806  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:33:21] d2.utils.events INFO:  eta: 1:10:50  iter: 4039  total_loss: 0.3532  loss_cls: 0.04671  loss_box_reg: 0.07842  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.07423  time: 0.7148  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:33:35] d2.utils.events INFO:  eta: 1:10:35  iter: 4059  total_loss: 0.3952  loss_cls: 0.05662  loss_box_reg: 0.09804  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.07517  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:33:49] d2.utils.events INFO:  eta: 1:10:21  iter: 4079  total_loss: 0.4209  loss_cls: 0.0497  loss_box_reg: 0.09403  loss_rpn_cls: 0.1653  loss_rpn_loc: 0.07173  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:34:04] d2.utils.events INFO:  eta: 1:10:06  iter: 4099  total_loss: 0.4046  loss_cls: 0.0468  loss_box_reg: 0.09724  loss_rpn_cls: 0.139  loss_rpn_loc: 0.07808  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:34:18] d2.utils.events INFO:  eta: 1:09:52  iter: 4119  total_loss: 0.3748  loss_cls: 0.04927  loss_box_reg: 0.07739  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.07182  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:34:32] d2.utils.events INFO:  eta: 1:09:38  iter: 4139  total_loss: 0.4087  loss_cls: 0.04686  loss_box_reg: 0.07802  loss_rpn_cls: 0.1507  loss_rpn_loc: 0.1084  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:34:47] d2.utils.events INFO:  eta: 1:09:23  iter: 4159  total_loss: 0.4344  loss_cls: 0.0586  loss_box_reg: 0.0718  loss_rpn_cls: 0.1762  loss_rpn_loc: 0.088  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:35:01] d2.utils.events INFO:  eta: 1:09:09  iter: 4179  total_loss: 0.3803  loss_cls: 0.05118  loss_box_reg: 0.08758  loss_rpn_cls: 0.127  loss_rpn_loc: 0.09895  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:35:15] d2.utils.events INFO:  eta: 1:08:54  iter: 4199  total_loss: 0.4039  loss_cls: 0.04929  loss_box_reg: 0.08535  loss_rpn_cls: 0.1341  loss_rpn_loc: 0.1131  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:35:30] d2.utils.events INFO:  eta: 1:08:40  iter: 4219  total_loss: 0.3988  loss_cls: 0.04859  loss_box_reg: 0.09882  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.1164  time: 0.7149  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 16:35:44] d2.utils.events INFO:  eta: 1:08:25  iter: 4239  total_loss: 0.3505  loss_cls: 0.04294  loss_box_reg: 0.08616  loss_rpn_cls: 0.1403  loss_rpn_loc: 0.09286  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:35:58] d2.utils.events INFO:  eta: 1:08:10  iter: 4259  total_loss: 0.336  loss_cls: 0.0457  loss_box_reg: 0.08413  loss_rpn_cls: 0.1276  loss_rpn_loc: 0.07656  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:36:13] d2.utils.events INFO:  eta: 1:07:56  iter: 4279  total_loss: 0.4019  loss_cls: 0.03883  loss_box_reg: 0.0758  loss_rpn_cls: 0.1482  loss_rpn_loc: 0.1099  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:36:27] d2.utils.events INFO:  eta: 1:07:42  iter: 4299  total_loss: 0.4412  loss_cls: 0.05475  loss_box_reg: 0.09101  loss_rpn_cls: 0.1517  loss_rpn_loc: 0.1179  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:36:41] d2.utils.events INFO:  eta: 1:07:28  iter: 4319  total_loss: 0.3467  loss_cls: 0.04994  loss_box_reg: 0.08849  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.0641  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:36:56] d2.utils.events INFO:  eta: 1:07:14  iter: 4339  total_loss: 0.3893  loss_cls: 0.04436  loss_box_reg: 0.09172  loss_rpn_cls: 0.1325  loss_rpn_loc: 0.09141  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:37:10] d2.utils.events INFO:  eta: 1:07:00  iter: 4359  total_loss: 0.4064  loss_cls: 0.03756  loss_box_reg: 0.08221  loss_rpn_cls: 0.1343  loss_rpn_loc: 0.08105  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:37:24] d2.utils.events INFO:  eta: 1:06:45  iter: 4379  total_loss: 0.3481  loss_cls: 0.04947  loss_box_reg: 0.08567  loss_rpn_cls: 0.1433  loss_rpn_loc: 0.08146  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:37:38] d2.utils.events INFO:  eta: 1:06:31  iter: 4399  total_loss: 0.3547  loss_cls: 0.05557  loss_box_reg: 0.07847  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.06903  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:37:53] d2.utils.events INFO:  eta: 1:06:17  iter: 4419  total_loss: 0.3826  loss_cls: 0.04431  loss_box_reg: 0.09151  loss_rpn_cls: 0.1162  loss_rpn_loc: 0.07407  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:38:07] d2.utils.events INFO:  eta: 1:06:03  iter: 4439  total_loss: 0.4104  loss_cls: 0.04584  loss_box_reg: 0.09403  loss_rpn_cls: 0.1453  loss_rpn_loc: 0.1067  time: 0.7149  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:38:21] d2.utils.events INFO:  eta: 1:05:49  iter: 4459  total_loss: 0.3696  loss_cls: 0.04959  loss_box_reg: 0.08634  loss_rpn_cls: 0.1802  loss_rpn_loc: 0.05821  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:38:36] d2.utils.events INFO:  eta: 1:05:35  iter: 4479  total_loss: 0.4451  loss_cls: 0.05399  loss_box_reg: 0.09944  loss_rpn_cls: 0.1693  loss_rpn_loc: 0.04891  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:38:50] d2.utils.events INFO:  eta: 1:05:20  iter: 4499  total_loss: 0.393  loss_cls: 0.048  loss_box_reg: 0.1002  loss_rpn_cls: 0.1611  loss_rpn_loc: 0.07118  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:39:04] d2.utils.events INFO:  eta: 1:05:07  iter: 4519  total_loss: 0.37  loss_cls: 0.04689  loss_box_reg: 0.0919  loss_rpn_cls: 0.112  loss_rpn_loc: 0.08932  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:39:19] d2.utils.events INFO:  eta: 1:04:52  iter: 4539  total_loss: 0.3711  loss_cls: 0.04948  loss_box_reg: 0.07901  loss_rpn_cls: 0.1319  loss_rpn_loc: 0.07347  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:39:33] d2.utils.events INFO:  eta: 1:04:37  iter: 4559  total_loss: 0.3935  loss_cls: 0.05922  loss_box_reg: 0.09666  loss_rpn_cls: 0.1543  loss_rpn_loc: 0.08483  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:39:47] d2.utils.events INFO:  eta: 1:04:24  iter: 4579  total_loss: 0.3765  loss_cls: 0.04755  loss_box_reg: 0.09797  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.06284  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:40:02] d2.utils.events INFO:  eta: 1:04:10  iter: 4599  total_loss: 0.3371  loss_cls: 0.0451  loss_box_reg: 0.08908  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.07618  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:40:16] d2.utils.events INFO:  eta: 1:03:56  iter: 4619  total_loss: 0.3741  loss_cls: 0.05973  loss_box_reg: 0.0808  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.06835  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:40:30] d2.utils.events INFO:  eta: 1:03:42  iter: 4639  total_loss: 0.3566  loss_cls: 0.04365  loss_box_reg: 0.07443  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.09757  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:40:45] d2.utils.events INFO:  eta: 1:03:28  iter: 4659  total_loss: 0.3314  loss_cls: 0.03911  loss_box_reg: 0.06886  loss_rpn_cls: 0.122  loss_rpn_loc: 0.06821  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:40:59] d2.utils.events INFO:  eta: 1:03:14  iter: 4679  total_loss: 0.332  loss_cls: 0.04151  loss_box_reg: 0.07154  loss_rpn_cls: 0.144  loss_rpn_loc: 0.06265  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:41:14] d2.utils.events INFO:  eta: 1:03:00  iter: 4699  total_loss: 0.3709  loss_cls: 0.04528  loss_box_reg: 0.08448  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.06907  time: 0.7150  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:41:28] d2.utils.events INFO:  eta: 1:02:47  iter: 4719  total_loss: 0.3924  loss_cls: 0.05213  loss_box_reg: 0.07682  loss_rpn_cls: 0.1517  loss_rpn_loc: 0.1017  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:41:42] d2.utils.events INFO:  eta: 1:02:32  iter: 4739  total_loss: 0.3833  loss_cls: 0.04298  loss_box_reg: 0.08337  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.09623  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:41:56] d2.utils.events INFO:  eta: 1:02:16  iter: 4759  total_loss: 0.3402  loss_cls: 0.04613  loss_box_reg: 0.07891  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.05053  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:42:10] d2.utils.events INFO:  eta: 1:02:02  iter: 4779  total_loss: 0.3412  loss_cls: 0.04478  loss_box_reg: 0.08689  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.07343  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:42:25] d2.utils.events INFO:  eta: 1:01:48  iter: 4799  total_loss: 0.3677  loss_cls: 0.04007  loss_box_reg: 0.07975  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.08474  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:42:39] d2.utils.events INFO:  eta: 1:01:34  iter: 4819  total_loss: 0.3525  loss_cls: 0.04515  loss_box_reg: 0.07879  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.06718  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:42:53] d2.utils.events INFO:  eta: 1:01:19  iter: 4839  total_loss: 0.3543  loss_cls: 0.04717  loss_box_reg: 0.09574  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.07365  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:43:08] d2.utils.events INFO:  eta: 1:01:06  iter: 4859  total_loss: 0.3596  loss_cls: 0.05005  loss_box_reg: 0.09955  loss_rpn_cls: 0.139  loss_rpn_loc: 0.05802  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:43:22] d2.utils.events INFO:  eta: 1:00:52  iter: 4879  total_loss: 0.4073  loss_cls: 0.04745  loss_box_reg: 0.08843  loss_rpn_cls: 0.1331  loss_rpn_loc: 0.09855  time: 0.7149  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:43:36] d2.utils.events INFO:  eta: 1:00:38  iter: 4899  total_loss: 0.3303  loss_cls: 0.04849  loss_box_reg: 0.08957  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.07257  time: 0.7149  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 16:43:51] d2.utils.events INFO:  eta: 1:00:24  iter: 4919  total_loss: 0.4057  loss_cls: 0.05203  loss_box_reg: 0.1035  loss_rpn_cls: 0.1705  loss_rpn_loc: 0.07249  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:44:05] d2.utils.events INFO:  eta: 1:00:10  iter: 4939  total_loss: 0.4013  loss_cls: 0.06345  loss_box_reg: 0.1063  loss_rpn_cls: 0.1694  loss_rpn_loc: 0.06721  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:44:20] d2.utils.events INFO:  eta: 0:59:56  iter: 4959  total_loss: 0.413  loss_cls: 0.04987  loss_box_reg: 0.09674  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.07274  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:44:34] d2.utils.events INFO:  eta: 0:59:42  iter: 4979  total_loss: 0.4072  loss_cls: 0.05925  loss_box_reg: 0.1105  loss_rpn_cls: 0.1463  loss_rpn_loc: 0.06547  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:44:48] d2.engine.hooks INFO: Running precise-BN for 200 iterations...  Note that this could produce different statistics every time.
[11/16 16:44:48] fvcore.nn.precise_bn INFO: Computing precise BN statistics for 43 BN layers ...
[11/16 16:45:13] d2.engine.hooks INFO: Running precise-BN ... 100/200 iterations.
[11/16 16:45:38] d2.engine.hooks INFO: Running precise-BN ... 200/200 iterations.
[11/16 16:45:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/model_0004999.pth
[11/16 16:45:38] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 12032        |
|            |              |[0m
[11/16 16:45:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 16:45:38] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[11/16 16:45:38] d2.data.common INFO: Serialized dataset takes 1.61 MiB
[11/16 16:45:38] d2.evaluation.coco_evaluation INFO: 'voc_2007_test_CAD_coco_style' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[11/16 16:45:38] d2.data.datasets.coco INFO: Converting annotations of dataset 'voc_2007_test_CAD_coco_style' to COCO format ...)
[11/16 16:45:38] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[11/16 16:45:40] d2.data.datasets.coco INFO: Conversion finished, #images: 4952, #annotations: 12032
[11/16 16:45:40] d2.data.datasets.coco INFO: Caching COCO format annotations at './outputs/RN50_DINO_FRCNN_VOC07_CAD/inference/voc_2007_test_CAD_coco_style_coco_format.json' ...
[11/16 16:45:40] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[11/16 16:45:41] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0010 s/iter. Inference: 0.0529 s/iter. Eval: 0.0002 s/iter. Total: 0.0541 s/iter. ETA=0:04:27
[11/16 16:45:46] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0009 s/iter. Inference: 0.0512 s/iter. Eval: 0.0002 s/iter. Total: 0.0523 s/iter. ETA=0:04:13
[11/16 16:45:51] d2.evaluation.evaluator INFO: Inference done 200/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:04:12
[11/16 16:45:56] d2.evaluation.evaluator INFO: Inference done 294/4952. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0002 s/iter. Total: 0.0533 s/iter. ETA=0:04:08
[11/16 16:46:01] d2.evaluation.evaluator INFO: Inference done 388/4952. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0002 s/iter. Total: 0.0533 s/iter. ETA=0:04:03
[11/16 16:46:06] d2.evaluation.evaluator INFO: Inference done 480/4952. Dataloading: 0.0009 s/iter. Inference: 0.0524 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:03:59
[11/16 16:46:11] d2.evaluation.evaluator INFO: Inference done 576/4952. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0002 s/iter. Total: 0.0534 s/iter. ETA=0:03:53
[11/16 16:46:16] d2.evaluation.evaluator INFO: Inference done 672/4952. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0002 s/iter. Total: 0.0533 s/iter. ETA=0:03:47
[11/16 16:46:21] d2.evaluation.evaluator INFO: Inference done 766/4952. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0002 s/iter. Total: 0.0533 s/iter. ETA=0:03:43
[11/16 16:46:26] d2.evaluation.evaluator INFO: Inference done 861/4952. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:03:37
[11/16 16:46:31] d2.evaluation.evaluator INFO: Inference done 958/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:03:32
[11/16 16:46:36] d2.evaluation.evaluator INFO: Inference done 1052/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:03:27
[11/16 16:46:41] d2.evaluation.evaluator INFO: Inference done 1147/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:03:22
[11/16 16:46:46] d2.evaluation.evaluator INFO: Inference done 1241/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:03:17
[11/16 16:46:51] d2.evaluation.evaluator INFO: Inference done 1335/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:03:12
[11/16 16:46:56] d2.evaluation.evaluator INFO: Inference done 1430/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:03:07
[11/16 16:47:01] d2.evaluation.evaluator INFO: Inference done 1527/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:03:01
[11/16 16:47:06] d2.evaluation.evaluator INFO: Inference done 1622/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:56
[11/16 16:47:11] d2.evaluation.evaluator INFO: Inference done 1715/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:51
[11/16 16:47:16] d2.evaluation.evaluator INFO: Inference done 1812/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0530 s/iter. ETA=0:02:46
[11/16 16:47:21] d2.evaluation.evaluator INFO: Inference done 1907/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:41
[11/16 16:47:27] d2.evaluation.evaluator INFO: Inference done 2001/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:36
[11/16 16:47:32] d2.evaluation.evaluator INFO: Inference done 2097/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:31
[11/16 16:47:37] d2.evaluation.evaluator INFO: Inference done 2191/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:26
[11/16 16:47:42] d2.evaluation.evaluator INFO: Inference done 2286/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:21
[11/16 16:47:47] d2.evaluation.evaluator INFO: Inference done 2380/4952. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:16
[11/16 16:47:52] d2.evaluation.evaluator INFO: Inference done 2473/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:02:11
[11/16 16:47:57] d2.evaluation.evaluator INFO: Inference done 2565/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:02:06
[11/16 16:48:02] d2.evaluation.evaluator INFO: Inference done 2661/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:02:01
[11/16 16:48:07] d2.evaluation.evaluator INFO: Inference done 2756/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:56
[11/16 16:48:12] d2.evaluation.evaluator INFO: Inference done 2850/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:01:51
[11/16 16:48:17] d2.evaluation.evaluator INFO: Inference done 2945/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:01:46
[11/16 16:48:22] d2.evaluation.evaluator INFO: Inference done 3041/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:41
[11/16 16:48:27] d2.evaluation.evaluator INFO: Inference done 3136/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:36
[11/16 16:48:32] d2.evaluation.evaluator INFO: Inference done 3229/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:31
[11/16 16:48:37] d2.evaluation.evaluator INFO: Inference done 3324/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:26
[11/16 16:48:42] d2.evaluation.evaluator INFO: Inference done 3419/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:21
[11/16 16:48:47] d2.evaluation.evaluator INFO: Inference done 3513/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:01:16
[11/16 16:48:52] d2.evaluation.evaluator INFO: Inference done 3608/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:11
[11/16 16:48:57] d2.evaluation.evaluator INFO: Inference done 3701/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:01:06
[11/16 16:49:02] d2.evaluation.evaluator INFO: Inference done 3798/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:01:01
[11/16 16:49:07] d2.evaluation.evaluator INFO: Inference done 3893/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:00:56
[11/16 16:49:12] d2.evaluation.evaluator INFO: Inference done 3986/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:51
[11/16 16:49:17] d2.evaluation.evaluator INFO: Inference done 4080/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:46
[11/16 16:49:22] d2.evaluation.evaluator INFO: Inference done 4173/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:41
[11/16 16:49:27] d2.evaluation.evaluator INFO: Inference done 4269/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:36
[11/16 16:49:32] d2.evaluation.evaluator INFO: Inference done 4365/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:31
[11/16 16:49:37] d2.evaluation.evaluator INFO: Inference done 4460/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:00:26
[11/16 16:49:42] d2.evaluation.evaluator INFO: Inference done 4554/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0531 s/iter. ETA=0:00:21
[11/16 16:49:47] d2.evaluation.evaluator INFO: Inference done 4648/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:16
[11/16 16:49:52] d2.evaluation.evaluator INFO: Inference done 4740/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:11
[11/16 16:49:57] d2.evaluation.evaluator INFO: Inference done 4837/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:06
[11/16 16:50:03] d2.evaluation.evaluator INFO: Inference done 4932/4952. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0002 s/iter. Total: 0.0532 s/iter. ETA=0:00:01
[11/16 16:50:04] d2.evaluation.evaluator INFO: Total inference time: 0:04:23.016615 (0.053167 s / iter per device, on 1 devices)
[11/16 16:50:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:17 (0.051991 s / iter per device, on 1 devices)
[11/16 16:50:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 16:50:04] d2.evaluation.coco_evaluation INFO: Saving results to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/inference/coco_instances_results.json
[11/16 16:50:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 16:50:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 16:50:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.30 seconds.
[11/16 16:50:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 16:50:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.10 seconds.
[11/16 16:50:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.162 | 22.376 | 2.947  | 0.000 | 0.594 | 10.886 |
[11/16 16:50:04] d2.engine.defaults INFO: Evaluation results for voc_2007_test_CAD_coco_style in csv format:
[11/16 16:50:04] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 16:50:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 16:50:04] d2.evaluation.testing INFO: copypaste: 7.1623,22.3761,2.9475,0.0000,0.5941,10.8862
[11/16 16:50:04] d2.utils.events INFO:  eta: 0:59:27  iter: 4999  total_loss: 0.4064  loss_cls: 0.05092  loss_box_reg: 0.09542  loss_rpn_cls: 0.1504  loss_rpn_loc: 0.07884  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:50:19] d2.utils.events INFO:  eta: 0:59:12  iter: 5019  total_loss: 0.4391  loss_cls: 0.05703  loss_box_reg: 0.1069  loss_rpn_cls: 0.1601  loss_rpn_loc: 0.1125  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:50:33] d2.utils.events INFO:  eta: 0:58:58  iter: 5039  total_loss: 0.3756  loss_cls: 0.0523  loss_box_reg: 0.08751  loss_rpn_cls: 0.1562  loss_rpn_loc: 0.07205  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:50:47] d2.utils.events INFO:  eta: 0:58:44  iter: 5059  total_loss: 0.4011  loss_cls: 0.05054  loss_box_reg: 0.1043  loss_rpn_cls: 0.1586  loss_rpn_loc: 0.08583  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:51:01] d2.utils.events INFO:  eta: 0:58:29  iter: 5079  total_loss: 0.4003  loss_cls: 0.0542  loss_box_reg: 0.09798  loss_rpn_cls: 0.1513  loss_rpn_loc: 0.08118  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:51:16] d2.utils.events INFO:  eta: 0:58:15  iter: 5099  total_loss: 0.3666  loss_cls: 0.03937  loss_box_reg: 0.07633  loss_rpn_cls: 0.136  loss_rpn_loc: 0.12  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:51:30] d2.utils.events INFO:  eta: 0:58:01  iter: 5119  total_loss: 0.4241  loss_cls: 0.0518  loss_box_reg: 0.0917  loss_rpn_cls: 0.144  loss_rpn_loc: 0.11  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:51:44] d2.utils.events INFO:  eta: 0:57:47  iter: 5139  total_loss: 0.405  loss_cls: 0.0532  loss_box_reg: 0.09338  loss_rpn_cls: 0.1762  loss_rpn_loc: 0.05332  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:51:59] d2.utils.events INFO:  eta: 0:57:33  iter: 5159  total_loss: 0.3893  loss_cls: 0.0451  loss_box_reg: 0.09255  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.1014  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:52:13] d2.utils.events INFO:  eta: 0:57:18  iter: 5179  total_loss: 0.3644  loss_cls: 0.0453  loss_box_reg: 0.09213  loss_rpn_cls: 0.1276  loss_rpn_loc: 0.06686  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:52:27] d2.utils.events INFO:  eta: 0:57:05  iter: 5199  total_loss: 0.4152  loss_cls: 0.05254  loss_box_reg: 0.09691  loss_rpn_cls: 0.115  loss_rpn_loc: 0.1515  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:52:42] d2.utils.events INFO:  eta: 0:56:50  iter: 5219  total_loss: 0.3737  loss_cls: 0.04623  loss_box_reg: 0.07648  loss_rpn_cls: 0.1595  loss_rpn_loc: 0.08571  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:52:56] d2.utils.events INFO:  eta: 0:56:36  iter: 5239  total_loss: 0.3272  loss_cls: 0.03663  loss_box_reg: 0.08508  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.07052  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:53:10] d2.utils.events INFO:  eta: 0:56:22  iter: 5259  total_loss: 0.3884  loss_cls: 0.05618  loss_box_reg: 0.1102  loss_rpn_cls: 0.1645  loss_rpn_loc: 0.06866  time: 0.7149  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:53:25] d2.utils.events INFO:  eta: 0:56:09  iter: 5279  total_loss: 0.3836  loss_cls: 0.04495  loss_box_reg: 0.08204  loss_rpn_cls: 0.1618  loss_rpn_loc: 0.08726  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:53:39] d2.utils.events INFO:  eta: 0:55:54  iter: 5299  total_loss: 0.3579  loss_cls: 0.04855  loss_box_reg: 0.08373  loss_rpn_cls: 0.1392  loss_rpn_loc: 0.05533  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:53:53] d2.utils.events INFO:  eta: 0:55:40  iter: 5319  total_loss: 0.3943  loss_cls: 0.04637  loss_box_reg: 0.08361  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.1123  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:54:08] d2.utils.events INFO:  eta: 0:55:26  iter: 5339  total_loss: 0.3701  loss_cls: 0.03756  loss_box_reg: 0.09128  loss_rpn_cls: 0.1429  loss_rpn_loc: 0.08009  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:54:22] d2.utils.events INFO:  eta: 0:55:11  iter: 5359  total_loss: 0.352  loss_cls: 0.04217  loss_box_reg: 0.07674  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1075  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:54:36] d2.utils.events INFO:  eta: 0:54:57  iter: 5379  total_loss: 0.3972  loss_cls: 0.03796  loss_box_reg: 0.07857  loss_rpn_cls: 0.14  loss_rpn_loc: 0.09753  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:54:51] d2.utils.events INFO:  eta: 0:54:43  iter: 5399  total_loss: 0.352  loss_cls: 0.0397  loss_box_reg: 0.08572  loss_rpn_cls: 0.1226  loss_rpn_loc: 0.08072  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:55:05] d2.utils.events INFO:  eta: 0:54:29  iter: 5419  total_loss: 0.4169  loss_cls: 0.05016  loss_box_reg: 0.085  loss_rpn_cls: 0.184  loss_rpn_loc: 0.06624  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:55:19] d2.utils.events INFO:  eta: 0:54:15  iter: 5439  total_loss: 0.3025  loss_cls: 0.03838  loss_box_reg: 0.0799  loss_rpn_cls: 0.127  loss_rpn_loc: 0.06082  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:55:34] d2.utils.events INFO:  eta: 0:54:01  iter: 5459  total_loss: 0.3438  loss_cls: 0.04773  loss_box_reg: 0.09272  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.08072  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:55:48] d2.utils.events INFO:  eta: 0:53:45  iter: 5479  total_loss: 0.37  loss_cls: 0.04589  loss_box_reg: 0.08943  loss_rpn_cls: 0.1346  loss_rpn_loc: 0.05733  time: 0.7148  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 16:56:02] d2.utils.events INFO:  eta: 0:53:31  iter: 5499  total_loss: 0.3935  loss_cls: 0.05922  loss_box_reg: 0.0878  loss_rpn_cls: 0.1738  loss_rpn_loc: 0.06187  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:56:16] d2.utils.events INFO:  eta: 0:53:16  iter: 5519  total_loss: 0.4058  loss_cls: 0.05478  loss_box_reg: 0.09353  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.09938  time: 0.7148  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:56:31] d2.utils.events INFO:  eta: 0:53:03  iter: 5539  total_loss: 0.3764  loss_cls: 0.04817  loss_box_reg: 0.09504  loss_rpn_cls: 0.1369  loss_rpn_loc: 0.06598  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:56:45] d2.utils.events INFO:  eta: 0:52:47  iter: 5559  total_loss: 0.3932  loss_cls: 0.05447  loss_box_reg: 0.09103  loss_rpn_cls: 0.1383  loss_rpn_loc: 0.0979  time: 0.7148  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:56:59] d2.utils.events INFO:  eta: 0:52:33  iter: 5579  total_loss: 0.4038  loss_cls: 0.04849  loss_box_reg: 0.08248  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.08847  time: 0.7148  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:57:13] d2.utils.events INFO:  eta: 0:52:19  iter: 5599  total_loss: 0.3698  loss_cls: 0.04911  loss_box_reg: 0.09365  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.07324  time: 0.7148  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:57:28] d2.utils.events INFO:  eta: 0:52:05  iter: 5619  total_loss: 0.3656  loss_cls: 0.05141  loss_box_reg: 0.09357  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.08982  time: 0.7148  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:57:42] d2.utils.events INFO:  eta: 0:51:50  iter: 5639  total_loss: 0.3641  loss_cls: 0.05109  loss_box_reg: 0.09228  loss_rpn_cls: 0.1227  loss_rpn_loc: 0.06298  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:57:57] d2.utils.events INFO:  eta: 0:51:37  iter: 5659  total_loss: 0.4029  loss_cls: 0.04388  loss_box_reg: 0.07531  loss_rpn_cls: 0.1359  loss_rpn_loc: 0.09612  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:58:11] d2.utils.events INFO:  eta: 0:51:22  iter: 5679  total_loss: 0.3768  loss_cls: 0.04457  loss_box_reg: 0.08074  loss_rpn_cls: 0.1565  loss_rpn_loc: 0.1109  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:58:26] d2.utils.events INFO:  eta: 0:51:07  iter: 5699  total_loss: 0.3658  loss_cls: 0.04432  loss_box_reg: 0.0831  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.09632  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 16:58:40] d2.utils.events INFO:  eta: 0:50:53  iter: 5719  total_loss: 0.3871  loss_cls: 0.04706  loss_box_reg: 0.08034  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.09634  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:58:54] d2.utils.events INFO:  eta: 0:50:40  iter: 5739  total_loss: 0.3873  loss_cls: 0.05447  loss_box_reg: 0.1043  loss_rpn_cls: 0.137  loss_rpn_loc: 0.07309  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 16:59:09] d2.utils.events INFO:  eta: 0:50:26  iter: 5759  total_loss: 0.3743  loss_cls: 0.03663  loss_box_reg: 0.07846  loss_rpn_cls: 0.1445  loss_rpn_loc: 0.08589  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 16:59:23] d2.utils.events INFO:  eta: 0:50:12  iter: 5779  total_loss: 0.3647  loss_cls: 0.04786  loss_box_reg: 0.08422  loss_rpn_cls: 0.1563  loss_rpn_loc: 0.06503  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:59:37] d2.utils.events INFO:  eta: 0:49:58  iter: 5799  total_loss: 0.4316  loss_cls: 0.05262  loss_box_reg: 0.08405  loss_rpn_cls: 0.1493  loss_rpn_loc: 0.09357  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 16:59:52] d2.utils.events INFO:  eta: 0:49:44  iter: 5819  total_loss: 0.4367  loss_cls: 0.064  loss_box_reg: 0.1113  loss_rpn_cls: 0.1335  loss_rpn_loc: 0.0928  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:00:06] d2.utils.events INFO:  eta: 0:49:30  iter: 5839  total_loss: 0.3669  loss_cls: 0.04178  loss_box_reg: 0.08633  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.09308  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:00:20] d2.utils.events INFO:  eta: 0:49:15  iter: 5859  total_loss: 0.3841  loss_cls: 0.04767  loss_box_reg: 0.09745  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.08409  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:00:34] d2.utils.events INFO:  eta: 0:48:59  iter: 5879  total_loss: 0.3807  loss_cls: 0.04861  loss_box_reg: 0.08903  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.0939  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:00:49] d2.utils.events INFO:  eta: 0:48:46  iter: 5899  total_loss: 0.3476  loss_cls: 0.04835  loss_box_reg: 0.0948  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.08649  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:01:03] d2.utils.events INFO:  eta: 0:48:30  iter: 5919  total_loss: 0.4045  loss_cls: 0.04699  loss_box_reg: 0.09361  loss_rpn_cls: 0.1675  loss_rpn_loc: 0.09729  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:01:17] d2.utils.events INFO:  eta: 0:48:16  iter: 5939  total_loss: 0.3386  loss_cls: 0.0415  loss_box_reg: 0.09424  loss_rpn_cls: 0.118  loss_rpn_loc: 0.09557  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:01:32] d2.utils.events INFO:  eta: 0:48:01  iter: 5959  total_loss: 0.3742  loss_cls: 0.04471  loss_box_reg: 0.09255  loss_rpn_cls: 0.127  loss_rpn_loc: 0.07038  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:01:46] d2.utils.events INFO:  eta: 0:47:48  iter: 5979  total_loss: 0.398  loss_cls: 0.05622  loss_box_reg: 0.1025  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.09728  time: 0.7149  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:02:00] d2.utils.events INFO:  eta: 0:47:33  iter: 5999  total_loss: 0.4076  loss_cls: 0.05256  loss_box_reg: 0.1122  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.08316  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:02:15] d2.utils.events INFO:  eta: 0:47:19  iter: 6019  total_loss: 0.365  loss_cls: 0.05045  loss_box_reg: 0.08778  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.08289  time: 0.7149  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:02:29] d2.utils.events INFO:  eta: 0:47:06  iter: 6039  total_loss: 0.3283  loss_cls: 0.04958  loss_box_reg: 0.0916  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.06558  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:02:44] d2.utils.events INFO:  eta: 0:46:52  iter: 6059  total_loss: 0.3439  loss_cls: 0.04102  loss_box_reg: 0.08247  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.1226  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:02:58] d2.utils.events INFO:  eta: 0:46:38  iter: 6079  total_loss: 0.4304  loss_cls: 0.05367  loss_box_reg: 0.09958  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.09436  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:03:12] d2.utils.events INFO:  eta: 0:46:23  iter: 6099  total_loss: 0.3822  loss_cls: 0.04838  loss_box_reg: 0.08387  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.108  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:03:26] d2.utils.events INFO:  eta: 0:46:09  iter: 6119  total_loss: 0.3766  loss_cls: 0.04562  loss_box_reg: 0.08801  loss_rpn_cls: 0.118  loss_rpn_loc: 0.09296  time: 0.7149  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:03:41] d2.utils.events INFO:  eta: 0:45:53  iter: 6139  total_loss: 0.3424  loss_cls: 0.04894  loss_box_reg: 0.1014  loss_rpn_cls: 0.1208  loss_rpn_loc: 0.09053  time: 0.7149  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:03:55] d2.utils.events INFO:  eta: 0:45:38  iter: 6159  total_loss: 0.3966  loss_cls: 0.05226  loss_box_reg: 0.1106  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.08989  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:04:10] d2.utils.events INFO:  eta: 0:45:26  iter: 6179  total_loss: 0.3719  loss_cls: 0.05196  loss_box_reg: 0.08721  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.07162  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:04:24] d2.utils.events INFO:  eta: 0:45:11  iter: 6199  total_loss: 0.3602  loss_cls: 0.04859  loss_box_reg: 0.09739  loss_rpn_cls: 0.135  loss_rpn_loc: 0.07108  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:04:39] d2.utils.events INFO:  eta: 0:44:58  iter: 6219  total_loss: 0.3595  loss_cls: 0.04493  loss_box_reg: 0.08609  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.09402  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:04:53] d2.utils.events INFO:  eta: 0:44:44  iter: 6239  total_loss: 0.3686  loss_cls: 0.04817  loss_box_reg: 0.09123  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.07807  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:05:07] d2.utils.events INFO:  eta: 0:44:30  iter: 6259  total_loss: 0.2997  loss_cls: 0.03965  loss_box_reg: 0.07594  loss_rpn_cls: 0.09714  loss_rpn_loc: 0.05568  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:05:22] d2.utils.events INFO:  eta: 0:44:15  iter: 6279  total_loss: 0.348  loss_cls: 0.05018  loss_box_reg: 0.09223  loss_rpn_cls: 0.113  loss_rpn_loc: 0.07199  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:05:36] d2.utils.events INFO:  eta: 0:44:01  iter: 6299  total_loss: 0.4191  loss_cls: 0.05166  loss_box_reg: 0.09764  loss_rpn_cls: 0.124  loss_rpn_loc: 0.1297  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:05:50] d2.utils.events INFO:  eta: 0:43:46  iter: 6319  total_loss: 0.3583  loss_cls: 0.04736  loss_box_reg: 0.07747  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.08453  time: 0.7150  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 17:06:05] d2.utils.events INFO:  eta: 0:43:31  iter: 6339  total_loss: 0.3592  loss_cls: 0.04548  loss_box_reg: 0.09582  loss_rpn_cls: 0.1318  loss_rpn_loc: 0.08071  time: 0.7150  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:06:19] d2.utils.events INFO:  eta: 0:43:16  iter: 6359  total_loss: 0.3206  loss_cls: 0.04051  loss_box_reg: 0.07838  loss_rpn_cls: 0.129  loss_rpn_loc: 0.06708  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:06:33] d2.utils.events INFO:  eta: 0:43:02  iter: 6379  total_loss: 0.4073  loss_cls: 0.05254  loss_box_reg: 0.09935  loss_rpn_cls: 0.1567  loss_rpn_loc: 0.1193  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:06:48] d2.utils.events INFO:  eta: 0:42:48  iter: 6399  total_loss: 0.3558  loss_cls: 0.04353  loss_box_reg: 0.08515  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.09572  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:07:02] d2.utils.events INFO:  eta: 0:42:32  iter: 6419  total_loss: 0.4326  loss_cls: 0.05251  loss_box_reg: 0.09971  loss_rpn_cls: 0.1428  loss_rpn_loc: 0.1012  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:07:16] d2.utils.events INFO:  eta: 0:42:19  iter: 6439  total_loss: 0.3575  loss_cls: 0.04247  loss_box_reg: 0.09776  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1049  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:07:31] d2.utils.events INFO:  eta: 0:42:06  iter: 6459  total_loss: 0.3581  loss_cls: 0.04387  loss_box_reg: 0.08634  loss_rpn_cls: 0.09339  loss_rpn_loc: 0.108  time: 0.7150  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:07:45] d2.utils.events INFO:  eta: 0:41:52  iter: 6479  total_loss: 0.3099  loss_cls: 0.04261  loss_box_reg: 0.08879  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.06884  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:07:59] d2.utils.events INFO:  eta: 0:41:38  iter: 6499  total_loss: 0.4298  loss_cls: 0.04601  loss_box_reg: 0.08971  loss_rpn_cls: 0.1344  loss_rpn_loc: 0.1188  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:08:14] d2.utils.events INFO:  eta: 0:41:24  iter: 6519  total_loss: 0.4125  loss_cls: 0.05342  loss_box_reg: 0.1008  loss_rpn_cls: 0.1434  loss_rpn_loc: 0.1096  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:08:28] d2.utils.events INFO:  eta: 0:41:12  iter: 6539  total_loss: 0.327  loss_cls: 0.0415  loss_box_reg: 0.09089  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.09553  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:08:42] d2.utils.events INFO:  eta: 0:40:59  iter: 6559  total_loss: 0.4101  loss_cls: 0.04939  loss_box_reg: 0.1006  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.1221  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:08:57] d2.utils.events INFO:  eta: 0:40:45  iter: 6579  total_loss: 0.4008  loss_cls: 0.05325  loss_box_reg: 0.1015  loss_rpn_cls: 0.1477  loss_rpn_loc: 0.06915  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:09:11] d2.utils.events INFO:  eta: 0:40:29  iter: 6599  total_loss: 0.3819  loss_cls: 0.04741  loss_box_reg: 0.1124  loss_rpn_cls: 0.1327  loss_rpn_loc: 0.07218  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:09:25] d2.utils.events INFO:  eta: 0:40:14  iter: 6619  total_loss: 0.4097  loss_cls: 0.05656  loss_box_reg: 0.1171  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.05621  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:09:39] d2.utils.events INFO:  eta: 0:39:59  iter: 6639  total_loss: 0.3262  loss_cls: 0.04656  loss_box_reg: 0.0877  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.0897  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:09:54] d2.utils.events INFO:  eta: 0:39:44  iter: 6659  total_loss: 0.3698  loss_cls: 0.04614  loss_box_reg: 0.09878  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.09988  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:10:08] d2.utils.events INFO:  eta: 0:39:30  iter: 6679  total_loss: 0.3735  loss_cls: 0.04662  loss_box_reg: 0.09119  loss_rpn_cls: 0.1428  loss_rpn_loc: 0.07354  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:10:22] d2.utils.events INFO:  eta: 0:39:16  iter: 6699  total_loss: 0.3673  loss_cls: 0.04417  loss_box_reg: 0.1034  loss_rpn_cls: 0.1353  loss_rpn_loc: 0.09382  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:10:37] d2.utils.events INFO:  eta: 0:39:02  iter: 6719  total_loss: 0.3474  loss_cls: 0.0433  loss_box_reg: 0.08124  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.06343  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:10:51] d2.utils.events INFO:  eta: 0:38:48  iter: 6739  total_loss: 0.3647  loss_cls: 0.04318  loss_box_reg: 0.09173  loss_rpn_cls: 0.112  loss_rpn_loc: 0.09326  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:11:05] d2.utils.events INFO:  eta: 0:38:34  iter: 6759  total_loss: 0.336  loss_cls: 0.04341  loss_box_reg: 0.08419  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.08994  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:11:20] d2.utils.events INFO:  eta: 0:38:20  iter: 6779  total_loss: 0.3746  loss_cls: 0.04594  loss_box_reg: 0.1007  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.07612  time: 0.7151  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 17:11:34] d2.utils.events INFO:  eta: 0:38:04  iter: 6799  total_loss: 0.3108  loss_cls: 0.0441  loss_box_reg: 0.09177  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.07165  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:11:48] d2.utils.events INFO:  eta: 0:37:49  iter: 6819  total_loss: 0.3094  loss_cls: 0.05205  loss_box_reg: 0.08928  loss_rpn_cls: 0.08145  loss_rpn_loc: 0.07628  time: 0.7150  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:12:03] d2.utils.events INFO:  eta: 0:37:36  iter: 6839  total_loss: 0.3397  loss_cls: 0.04997  loss_box_reg: 0.09459  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.06002  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:12:17] d2.utils.events INFO:  eta: 0:37:22  iter: 6859  total_loss: 0.3607  loss_cls: 0.0509  loss_box_reg: 0.1006  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.06519  time: 0.7150  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:12:31] d2.utils.events INFO:  eta: 0:37:10  iter: 6879  total_loss: 0.343  loss_cls: 0.05078  loss_box_reg: 0.09717  loss_rpn_cls: 0.123  loss_rpn_loc: 0.08451  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:12:46] d2.utils.events INFO:  eta: 0:36:54  iter: 6899  total_loss: 0.3405  loss_cls: 0.03908  loss_box_reg: 0.09591  loss_rpn_cls: 0.08934  loss_rpn_loc: 0.09716  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:13:00] d2.utils.events INFO:  eta: 0:36:40  iter: 6919  total_loss: 0.3213  loss_cls: 0.04523  loss_box_reg: 0.08464  loss_rpn_cls: 0.09496  loss_rpn_loc: 0.07414  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:13:14] d2.utils.events INFO:  eta: 0:36:26  iter: 6939  total_loss: 0.3166  loss_cls: 0.0475  loss_box_reg: 0.0816  loss_rpn_cls: 0.09887  loss_rpn_loc: 0.0767  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:13:29] d2.utils.events INFO:  eta: 0:36:12  iter: 6959  total_loss: 0.3956  loss_cls: 0.06249  loss_box_reg: 0.114  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.09471  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:13:43] d2.utils.events INFO:  eta: 0:35:57  iter: 6979  total_loss: 0.3684  loss_cls: 0.05118  loss_box_reg: 0.0836  loss_rpn_cls: 0.1388  loss_rpn_loc: 0.08814  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:13:58] d2.utils.events INFO:  eta: 0:35:43  iter: 6999  total_loss: 0.296  loss_cls: 0.04341  loss_box_reg: 0.08121  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.05041  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:14:12] d2.utils.events INFO:  eta: 0:35:29  iter: 7019  total_loss: 0.3346  loss_cls: 0.03948  loss_box_reg: 0.09052  loss_rpn_cls: 0.09977  loss_rpn_loc: 0.1009  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:14:27] d2.utils.events INFO:  eta: 0:35:17  iter: 7039  total_loss: 0.3426  loss_cls: 0.04495  loss_box_reg: 0.09242  loss_rpn_cls: 0.09931  loss_rpn_loc: 0.09363  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:14:41] d2.utils.events INFO:  eta: 0:35:02  iter: 7059  total_loss: 0.3213  loss_cls: 0.04042  loss_box_reg: 0.07399  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.09229  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:14:55] d2.utils.events INFO:  eta: 0:34:47  iter: 7079  total_loss: 0.3447  loss_cls: 0.04265  loss_box_reg: 0.08534  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.08075  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:15:09] d2.utils.events INFO:  eta: 0:34:33  iter: 7099  total_loss: 0.3613  loss_cls: 0.04396  loss_box_reg: 0.08774  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.09626  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:15:24] d2.utils.events INFO:  eta: 0:34:19  iter: 7119  total_loss: 0.3772  loss_cls: 0.04961  loss_box_reg: 0.1126  loss_rpn_cls: 0.1246  loss_rpn_loc: 0.08888  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:15:38] d2.utils.events INFO:  eta: 0:34:04  iter: 7139  total_loss: 0.3185  loss_cls: 0.045  loss_box_reg: 0.09215  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.07526  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:15:52] d2.utils.events INFO:  eta: 0:33:50  iter: 7159  total_loss: 0.3183  loss_cls: 0.04857  loss_box_reg: 0.09217  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.07206  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:16:06] d2.utils.events INFO:  eta: 0:33:35  iter: 7179  total_loss: 0.3884  loss_cls: 0.04823  loss_box_reg: 0.09677  loss_rpn_cls: 0.1346  loss_rpn_loc: 0.08978  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:16:21] d2.utils.events INFO:  eta: 0:33:21  iter: 7199  total_loss: 0.3507  loss_cls: 0.04478  loss_box_reg: 0.09029  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.06556  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:16:35] d2.utils.events INFO:  eta: 0:33:07  iter: 7219  total_loss: 0.3048  loss_cls: 0.04362  loss_box_reg: 0.07804  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.08078  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:16:49] d2.utils.events INFO:  eta: 0:32:52  iter: 7239  total_loss: 0.3627  loss_cls: 0.04697  loss_box_reg: 0.1058  loss_rpn_cls: 0.1227  loss_rpn_loc: 0.08436  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:17:04] d2.utils.events INFO:  eta: 0:32:38  iter: 7259  total_loss: 0.3429  loss_cls: 0.04465  loss_box_reg: 0.1023  loss_rpn_cls: 0.09535  loss_rpn_loc: 0.08652  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:17:18] d2.utils.events INFO:  eta: 0:32:24  iter: 7279  total_loss: 0.3108  loss_cls: 0.0358  loss_box_reg: 0.08524  loss_rpn_cls: 0.08795  loss_rpn_loc: 0.08623  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:17:33] d2.utils.events INFO:  eta: 0:32:09  iter: 7299  total_loss: 0.3366  loss_cls: 0.04583  loss_box_reg: 0.09949  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.07138  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:17:47] d2.utils.events INFO:  eta: 0:31:54  iter: 7319  total_loss: 0.2824  loss_cls: 0.03726  loss_box_reg: 0.07878  loss_rpn_cls: 0.09803  loss_rpn_loc: 0.06465  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:18:01] d2.utils.events INFO:  eta: 0:31:40  iter: 7339  total_loss: 0.3194  loss_cls: 0.04702  loss_box_reg: 0.09884  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.06743  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:18:15] d2.utils.events INFO:  eta: 0:31:26  iter: 7359  total_loss: 0.4214  loss_cls: 0.04583  loss_box_reg: 0.09916  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.1159  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:18:29] d2.utils.events INFO:  eta: 0:31:12  iter: 7379  total_loss: 0.3961  loss_cls: 0.05359  loss_box_reg: 0.1018  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.09877  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:18:44] d2.utils.events INFO:  eta: 0:30:58  iter: 7399  total_loss: 0.4002  loss_cls: 0.05466  loss_box_reg: 0.101  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.0911  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:18:58] d2.utils.events INFO:  eta: 0:30:44  iter: 7419  total_loss: 0.3912  loss_cls: 0.04455  loss_box_reg: 0.08686  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.09478  time: 0.7151  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 17:19:13] d2.utils.events INFO:  eta: 0:30:30  iter: 7439  total_loss: 0.3858  loss_cls: 0.04585  loss_box_reg: 0.08683  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.1301  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:19:27] d2.utils.events INFO:  eta: 0:30:15  iter: 7459  total_loss: 0.3724  loss_cls: 0.04932  loss_box_reg: 0.1069  loss_rpn_cls: 0.1235  loss_rpn_loc: 0.07946  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:19:41] d2.utils.events INFO:  eta: 0:30:00  iter: 7479  total_loss: 0.3906  loss_cls: 0.04807  loss_box_reg: 0.09342  loss_rpn_cls: 0.131  loss_rpn_loc: 0.07952  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:19:55] d2.utils.events INFO:  eta: 0:29:44  iter: 7499  total_loss: 0.3472  loss_cls: 0.05081  loss_box_reg: 0.09147  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.08651  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:20:10] d2.utils.events INFO:  eta: 0:29:31  iter: 7519  total_loss: 0.3507  loss_cls: 0.05904  loss_box_reg: 0.1086  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.07174  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:20:24] d2.utils.events INFO:  eta: 0:29:16  iter: 7539  total_loss: 0.3577  loss_cls: 0.04817  loss_box_reg: 0.09167  loss_rpn_cls: 0.08958  loss_rpn_loc: 0.07996  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:20:39] d2.utils.events INFO:  eta: 0:29:00  iter: 7559  total_loss: 0.3675  loss_cls: 0.04601  loss_box_reg: 0.1015  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.09584  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:20:53] d2.utils.events INFO:  eta: 0:28:46  iter: 7579  total_loss: 0.3336  loss_cls: 0.05331  loss_box_reg: 0.08109  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.08183  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:21:07] d2.utils.events INFO:  eta: 0:28:32  iter: 7599  total_loss: 0.3277  loss_cls: 0.0517  loss_box_reg: 0.08654  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.07295  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:21:22] d2.utils.events INFO:  eta: 0:28:18  iter: 7619  total_loss: 0.3907  loss_cls: 0.05007  loss_box_reg: 0.1145  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.1208  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:21:36] d2.utils.events INFO:  eta: 0:28:04  iter: 7639  total_loss: 0.3603  loss_cls: 0.04669  loss_box_reg: 0.09753  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.074  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:21:50] d2.utils.events INFO:  eta: 0:27:50  iter: 7659  total_loss: 0.3132  loss_cls: 0.03731  loss_box_reg: 0.08704  loss_rpn_cls: 0.07697  loss_rpn_loc: 0.09807  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:22:05] d2.utils.events INFO:  eta: 0:27:36  iter: 7679  total_loss: 0.3882  loss_cls: 0.04393  loss_box_reg: 0.09064  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.1004  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:22:19] d2.utils.events INFO:  eta: 0:27:22  iter: 7699  total_loss: 0.3941  loss_cls: 0.0465  loss_box_reg: 0.09783  loss_rpn_cls: 0.09513  loss_rpn_loc: 0.1236  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:22:34] d2.utils.events INFO:  eta: 0:27:07  iter: 7719  total_loss: 0.3386  loss_cls: 0.04895  loss_box_reg: 0.08657  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.06865  time: 0.7152  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:22:48] d2.utils.events INFO:  eta: 0:26:53  iter: 7739  total_loss: 0.3485  loss_cls: 0.03868  loss_box_reg: 0.08341  loss_rpn_cls: 0.117  loss_rpn_loc: 0.1029  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:23:02] d2.utils.events INFO:  eta: 0:26:39  iter: 7759  total_loss: 0.2873  loss_cls: 0.03794  loss_box_reg: 0.08371  loss_rpn_cls: 0.09995  loss_rpn_loc: 0.07724  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:23:17] d2.utils.events INFO:  eta: 0:26:26  iter: 7779  total_loss: 0.3318  loss_cls: 0.03859  loss_box_reg: 0.08688  loss_rpn_cls: 0.09601  loss_rpn_loc: 0.09975  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:23:31] d2.utils.events INFO:  eta: 0:26:12  iter: 7799  total_loss: 0.272  loss_cls: 0.03303  loss_box_reg: 0.08079  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.07622  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:23:45] d2.utils.events INFO:  eta: 0:25:58  iter: 7819  total_loss: 0.3605  loss_cls: 0.0548  loss_box_reg: 0.1041  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.06835  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:24:00] d2.utils.events INFO:  eta: 0:25:44  iter: 7839  total_loss: 0.3407  loss_cls: 0.05266  loss_box_reg: 0.09836  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.05599  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:24:14] d2.utils.events INFO:  eta: 0:25:29  iter: 7859  total_loss: 0.3751  loss_cls: 0.04875  loss_box_reg: 0.09309  loss_rpn_cls: 0.1193  loss_rpn_loc: 0.08226  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:24:28] d2.utils.events INFO:  eta: 0:25:15  iter: 7879  total_loss: 0.3374  loss_cls: 0.04465  loss_box_reg: 0.0909  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.0756  time: 0.7152  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:24:43] d2.utils.events INFO:  eta: 0:25:01  iter: 7899  total_loss: 0.3049  loss_cls: 0.03912  loss_box_reg: 0.08486  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.08059  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:24:57] d2.utils.events INFO:  eta: 0:24:47  iter: 7919  total_loss: 0.4159  loss_cls: 0.05014  loss_box_reg: 0.09916  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.08206  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:25:11] d2.utils.events INFO:  eta: 0:24:32  iter: 7939  total_loss: 0.3693  loss_cls: 0.04542  loss_box_reg: 0.1027  loss_rpn_cls: 0.09627  loss_rpn_loc: 0.1076  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:25:26] d2.utils.events INFO:  eta: 0:24:18  iter: 7959  total_loss: 0.3833  loss_cls: 0.04871  loss_box_reg: 0.09748  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.07523  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:25:40] d2.utils.events INFO:  eta: 0:24:04  iter: 7979  total_loss: 0.361  loss_cls: 0.05162  loss_box_reg: 0.09763  loss_rpn_cls: 0.11  loss_rpn_loc: 0.09022  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:25:55] d2.utils.events INFO:  eta: 0:23:49  iter: 7999  total_loss: 0.3735  loss_cls: 0.04296  loss_box_reg: 0.08003  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.09728  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:26:09] d2.utils.events INFO:  eta: 0:23:35  iter: 8019  total_loss: 0.3889  loss_cls: 0.04694  loss_box_reg: 0.08616  loss_rpn_cls: 0.1451  loss_rpn_loc: 0.08529  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:26:23] d2.utils.events INFO:  eta: 0:23:20  iter: 8039  total_loss: 0.35  loss_cls: 0.0456  loss_box_reg: 0.08749  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.09007  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:26:38] d2.utils.events INFO:  eta: 0:23:06  iter: 8059  total_loss: 0.332  loss_cls: 0.04485  loss_box_reg: 0.08703  loss_rpn_cls: 0.09085  loss_rpn_loc: 0.09204  time: 0.7152  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:26:52] d2.utils.events INFO:  eta: 0:22:51  iter: 8079  total_loss: 0.3154  loss_cls: 0.0395  loss_box_reg: 0.07724  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.07467  time: 0.7152  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 17:27:06] d2.utils.events INFO:  eta: 0:22:37  iter: 8099  total_loss: 0.3249  loss_cls: 0.04731  loss_box_reg: 0.1041  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.08124  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:27:21] d2.utils.events INFO:  eta: 0:22:23  iter: 8119  total_loss: 0.3557  loss_cls: 0.04935  loss_box_reg: 0.09067  loss_rpn_cls: 0.09906  loss_rpn_loc: 0.06114  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:27:35] d2.utils.events INFO:  eta: 0:22:09  iter: 8139  total_loss: 0.3368  loss_cls: 0.04974  loss_box_reg: 0.1047  loss_rpn_cls: 0.121  loss_rpn_loc: 0.06769  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:27:49] d2.utils.events INFO:  eta: 0:21:54  iter: 8159  total_loss: 0.3393  loss_cls: 0.05237  loss_box_reg: 0.09908  loss_rpn_cls: 0.0992  loss_rpn_loc: 0.06372  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:28:03] d2.utils.events INFO:  eta: 0:21:41  iter: 8179  total_loss: 0.3411  loss_cls: 0.04644  loss_box_reg: 0.1058  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.07841  time: 0.7152  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:28:18] d2.utils.events INFO:  eta: 0:21:26  iter: 8199  total_loss: 0.318  loss_cls: 0.04565  loss_box_reg: 0.09125  loss_rpn_cls: 0.112  loss_rpn_loc: 0.06509  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:28:32] d2.utils.events INFO:  eta: 0:21:11  iter: 8219  total_loss: 0.3401  loss_cls: 0.03918  loss_box_reg: 0.08857  loss_rpn_cls: 0.09395  loss_rpn_loc: 0.08011  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:28:46] d2.utils.events INFO:  eta: 0:20:57  iter: 8239  total_loss: 0.3436  loss_cls: 0.04471  loss_box_reg: 0.08844  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.07514  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:29:00] d2.utils.events INFO:  eta: 0:20:42  iter: 8259  total_loss: 0.3132  loss_cls: 0.04176  loss_box_reg: 0.07991  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.07194  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:29:15] d2.utils.events INFO:  eta: 0:20:28  iter: 8279  total_loss: 0.3657  loss_cls: 0.04787  loss_box_reg: 0.1092  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.09268  time: 0.7152  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:29:29] d2.utils.events INFO:  eta: 0:20:14  iter: 8299  total_loss: 0.3576  loss_cls: 0.0542  loss_box_reg: 0.102  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.07685  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:29:43] d2.utils.events INFO:  eta: 0:20:00  iter: 8319  total_loss: 0.394  loss_cls: 0.05014  loss_box_reg: 0.133  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.1137  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:29:58] d2.utils.events INFO:  eta: 0:19:46  iter: 8339  total_loss: 0.3496  loss_cls: 0.04385  loss_box_reg: 0.09657  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.09047  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:30:12] d2.utils.events INFO:  eta: 0:19:32  iter: 8359  total_loss: 0.3129  loss_cls: 0.04151  loss_box_reg: 0.09034  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.06125  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:30:27] d2.utils.events INFO:  eta: 0:19:17  iter: 8379  total_loss: 0.3488  loss_cls: 0.04356  loss_box_reg: 0.1002  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.08468  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:30:41] d2.utils.events INFO:  eta: 0:19:03  iter: 8399  total_loss: 0.3479  loss_cls: 0.0492  loss_box_reg: 0.08417  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.0804  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:30:55] d2.utils.events INFO:  eta: 0:18:48  iter: 8419  total_loss: 0.3469  loss_cls: 0.04737  loss_box_reg: 0.08898  loss_rpn_cls: 0.0957  loss_rpn_loc: 0.06388  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:31:09] d2.utils.events INFO:  eta: 0:18:34  iter: 8439  total_loss: 0.2948  loss_cls: 0.0484  loss_box_reg: 0.08896  loss_rpn_cls: 0.09139  loss_rpn_loc: 0.0565  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:31:24] d2.utils.events INFO:  eta: 0:18:20  iter: 8459  total_loss: 0.3488  loss_cls: 0.04498  loss_box_reg: 0.09465  loss_rpn_cls: 0.09464  loss_rpn_loc: 0.08765  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:31:38] d2.utils.events INFO:  eta: 0:18:06  iter: 8479  total_loss: 0.3111  loss_cls: 0.04423  loss_box_reg: 0.0858  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.07157  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:31:52] d2.utils.events INFO:  eta: 0:17:52  iter: 8499  total_loss: 0.3723  loss_cls: 0.04733  loss_box_reg: 0.09023  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.09478  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:32:07] d2.utils.events INFO:  eta: 0:17:37  iter: 8519  total_loss: 0.374  loss_cls: 0.05551  loss_box_reg: 0.1073  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.07022  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:32:21] d2.utils.events INFO:  eta: 0:17:23  iter: 8539  total_loss: 0.2925  loss_cls: 0.04773  loss_box_reg: 0.1015  loss_rpn_cls: 0.08771  loss_rpn_loc: 0.06219  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:32:35] d2.utils.events INFO:  eta: 0:17:08  iter: 8559  total_loss: 0.3057  loss_cls: 0.04699  loss_box_reg: 0.08582  loss_rpn_cls: 0.0925  loss_rpn_loc: 0.05103  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:32:49] d2.utils.events INFO:  eta: 0:16:54  iter: 8579  total_loss: 0.3127  loss_cls: 0.05118  loss_box_reg: 0.1004  loss_rpn_cls: 0.08697  loss_rpn_loc: 0.05703  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:33:04] d2.utils.events INFO:  eta: 0:16:40  iter: 8599  total_loss: 0.391  loss_cls: 0.0518  loss_box_reg: 0.0942  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1075  time: 0.7151  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 17:33:18] d2.utils.events INFO:  eta: 0:16:26  iter: 8619  total_loss: 0.3887  loss_cls: 0.05543  loss_box_reg: 0.0984  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.07948  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:33:32] d2.utils.events INFO:  eta: 0:16:11  iter: 8639  total_loss: 0.325  loss_cls: 0.04701  loss_box_reg: 0.08123  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.06584  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:33:46] d2.utils.events INFO:  eta: 0:15:57  iter: 8659  total_loss: 0.3534  loss_cls: 0.04212  loss_box_reg: 0.1001  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.09386  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:34:01] d2.utils.events INFO:  eta: 0:15:43  iter: 8679  total_loss: 0.3382  loss_cls: 0.03877  loss_box_reg: 0.08774  loss_rpn_cls: 0.09895  loss_rpn_loc: 0.1009  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:34:15] d2.utils.events INFO:  eta: 0:15:28  iter: 8699  total_loss: 0.3354  loss_cls: 0.03616  loss_box_reg: 0.0913  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.09365  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:34:29] d2.utils.events INFO:  eta: 0:15:14  iter: 8719  total_loss: 0.4315  loss_cls: 0.05394  loss_box_reg: 0.09969  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.09064  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:34:44] d2.utils.events INFO:  eta: 0:15:00  iter: 8739  total_loss: 0.3123  loss_cls: 0.03913  loss_box_reg: 0.08583  loss_rpn_cls: 0.0906  loss_rpn_loc: 0.08759  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:34:58] d2.utils.events INFO:  eta: 0:14:45  iter: 8759  total_loss: 0.3396  loss_cls: 0.04819  loss_box_reg: 0.1009  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.06402  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:35:12] d2.utils.events INFO:  eta: 0:14:31  iter: 8779  total_loss: 0.3412  loss_cls: 0.05947  loss_box_reg: 0.1107  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.08229  time: 0.7151  data_time: 0.0032  lr: 0.02  max_mem: 8272M
[11/16 17:35:27] d2.utils.events INFO:  eta: 0:14:17  iter: 8799  total_loss: 0.3223  loss_cls: 0.04933  loss_box_reg: 0.0962  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.07668  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:35:41] d2.utils.events INFO:  eta: 0:14:02  iter: 8819  total_loss: 0.3667  loss_cls: 0.05813  loss_box_reg: 0.106  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.07306  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:35:55] d2.utils.events INFO:  eta: 0:13:48  iter: 8839  total_loss: 0.3852  loss_cls: 0.05954  loss_box_reg: 0.09719  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.07254  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:36:10] d2.utils.events INFO:  eta: 0:13:33  iter: 8859  total_loss: 0.4  loss_cls: 0.043  loss_box_reg: 0.09324  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.09051  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:36:24] d2.utils.events INFO:  eta: 0:13:19  iter: 8879  total_loss: 0.3529  loss_cls: 0.05217  loss_box_reg: 0.08659  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.09496  time: 0.7151  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 17:36:38] d2.utils.events INFO:  eta: 0:13:05  iter: 8899  total_loss: 0.3527  loss_cls: 0.04796  loss_box_reg: 0.1021  loss_rpn_cls: 0.1397  loss_rpn_loc: 0.0675  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:36:52] d2.utils.events INFO:  eta: 0:12:50  iter: 8919  total_loss: 0.3801  loss_cls: 0.04819  loss_box_reg: 0.09096  loss_rpn_cls: 0.102  loss_rpn_loc: 0.09395  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:37:07] d2.utils.events INFO:  eta: 0:12:36  iter: 8939  total_loss: 0.3947  loss_cls: 0.05316  loss_box_reg: 0.1045  loss_rpn_cls: 0.1207  loss_rpn_loc: 0.09643  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:37:21] d2.utils.events INFO:  eta: 0:12:22  iter: 8959  total_loss: 0.3004  loss_cls: 0.03946  loss_box_reg: 0.08671  loss_rpn_cls: 0.08941  loss_rpn_loc: 0.06421  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:37:36] d2.utils.events INFO:  eta: 0:12:08  iter: 8979  total_loss: 0.3681  loss_cls: 0.04856  loss_box_reg: 0.09408  loss_rpn_cls: 0.09162  loss_rpn_loc: 0.07673  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:37:50] d2.utils.events INFO:  eta: 0:11:54  iter: 8999  total_loss: 0.3959  loss_cls: 0.04932  loss_box_reg: 0.1073  loss_rpn_cls: 0.09866  loss_rpn_loc: 0.09117  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:38:05] d2.utils.events INFO:  eta: 0:11:40  iter: 9019  total_loss: 0.3947  loss_cls: 0.04003  loss_box_reg: 0.09439  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.09188  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:38:19] d2.utils.events INFO:  eta: 0:11:25  iter: 9039  total_loss: 0.3585  loss_cls: 0.04896  loss_box_reg: 0.09806  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.07807  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:38:33] d2.utils.events INFO:  eta: 0:11:11  iter: 9059  total_loss: 0.3293  loss_cls: 0.03938  loss_box_reg: 0.07835  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.09484  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:38:48] d2.utils.events INFO:  eta: 0:10:57  iter: 9079  total_loss: 0.3299  loss_cls: 0.04533  loss_box_reg: 0.1038  loss_rpn_cls: 0.113  loss_rpn_loc: 0.05609  time: 0.7152  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:39:02] d2.utils.events INFO:  eta: 0:10:43  iter: 9099  total_loss: 0.3569  loss_cls: 0.04901  loss_box_reg: 0.09015  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.06653  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:39:16] d2.utils.events INFO:  eta: 0:10:28  iter: 9119  total_loss: 0.3666  loss_cls: 0.05364  loss_box_reg: 0.1085  loss_rpn_cls: 0.08607  loss_rpn_loc: 0.09484  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:39:31] d2.utils.events INFO:  eta: 0:10:14  iter: 9139  total_loss: 0.34  loss_cls: 0.04788  loss_box_reg: 0.09585  loss_rpn_cls: 0.08788  loss_rpn_loc: 0.06677  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:39:45] d2.utils.events INFO:  eta: 0:10:00  iter: 9159  total_loss: 0.3192  loss_cls: 0.05346  loss_box_reg: 0.1029  loss_rpn_cls: 0.08287  loss_rpn_loc: 0.06348  time: 0.7152  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:39:59] d2.utils.events INFO:  eta: 0:09:45  iter: 9179  total_loss: 0.3717  loss_cls: 0.04188  loss_box_reg: 0.1015  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.06579  time: 0.7152  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:40:14] d2.utils.events INFO:  eta: 0:09:31  iter: 9199  total_loss: 0.3272  loss_cls: 0.04065  loss_box_reg: 0.1014  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.07774  time: 0.7152  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:40:28] d2.utils.events INFO:  eta: 0:09:17  iter: 9219  total_loss: 0.3195  loss_cls: 0.04831  loss_box_reg: 0.0956  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.07932  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:40:42] d2.utils.events INFO:  eta: 0:09:02  iter: 9239  total_loss: 0.4154  loss_cls: 0.04401  loss_box_reg: 0.09095  loss_rpn_cls: 0.1561  loss_rpn_loc: 0.1345  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:40:57] d2.utils.events INFO:  eta: 0:08:48  iter: 9259  total_loss: 0.3436  loss_cls: 0.05158  loss_box_reg: 0.08025  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.072  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:41:11] d2.utils.events INFO:  eta: 0:08:34  iter: 9279  total_loss: 0.347  loss_cls: 0.04249  loss_box_reg: 0.1101  loss_rpn_cls: 0.08492  loss_rpn_loc: 0.09504  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:41:25] d2.utils.events INFO:  eta: 0:08:20  iter: 9299  total_loss: 0.2853  loss_cls: 0.04121  loss_box_reg: 0.08413  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.06812  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:41:39] d2.utils.events INFO:  eta: 0:08:05  iter: 9319  total_loss: 0.3493  loss_cls: 0.0513  loss_box_reg: 0.1017  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.07623  time: 0.7152  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:41:54] d2.utils.events INFO:  eta: 0:07:51  iter: 9339  total_loss: 0.3709  loss_cls: 0.04902  loss_box_reg: 0.08828  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.08959  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:42:08] d2.utils.events INFO:  eta: 0:07:37  iter: 9359  total_loss: 0.3329  loss_cls: 0.04594  loss_box_reg: 0.09475  loss_rpn_cls: 0.1242  loss_rpn_loc: 0.05128  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:42:22] d2.utils.events INFO:  eta: 0:07:22  iter: 9379  total_loss: 0.3484  loss_cls: 0.0508  loss_box_reg: 0.108  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.06707  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:42:37] d2.utils.events INFO:  eta: 0:07:08  iter: 9399  total_loss: 0.3134  loss_cls: 0.03755  loss_box_reg: 0.077  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.0973  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:42:51] d2.utils.events INFO:  eta: 0:06:54  iter: 9419  total_loss: 0.3022  loss_cls: 0.04156  loss_box_reg: 0.08113  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.07803  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:43:05] d2.utils.events INFO:  eta: 0:06:40  iter: 9439  total_loss: 0.3613  loss_cls: 0.04811  loss_box_reg: 0.1038  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.09095  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:43:19] d2.utils.events INFO:  eta: 0:06:25  iter: 9459  total_loss: 0.3211  loss_cls: 0.04209  loss_box_reg: 0.09416  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.07587  time: 0.7151  data_time: 0.0025  lr: 0.02  max_mem: 8272M
[11/16 17:43:33] d2.utils.events INFO:  eta: 0:06:11  iter: 9479  total_loss: 0.3606  loss_cls: 0.05043  loss_box_reg: 0.09364  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.1022  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:43:48] d2.utils.events INFO:  eta: 0:05:57  iter: 9499  total_loss: 0.3671  loss_cls: 0.05071  loss_box_reg: 0.105  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.07107  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:44:02] d2.utils.events INFO:  eta: 0:05:42  iter: 9519  total_loss: 0.3434  loss_cls: 0.05196  loss_box_reg: 0.1029  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.07595  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:44:16] d2.utils.events INFO:  eta: 0:05:28  iter: 9539  total_loss: 0.3132  loss_cls: 0.0427  loss_box_reg: 0.09444  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.07987  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:44:31] d2.utils.events INFO:  eta: 0:05:14  iter: 9559  total_loss: 0.3402  loss_cls: 0.04537  loss_box_reg: 0.08657  loss_rpn_cls: 0.11  loss_rpn_loc: 0.07514  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:44:45] d2.utils.events INFO:  eta: 0:04:59  iter: 9579  total_loss: 0.3198  loss_cls: 0.041  loss_box_reg: 0.08935  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.06456  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:44:59] d2.utils.events INFO:  eta: 0:04:45  iter: 9599  total_loss: 0.3612  loss_cls: 0.05201  loss_box_reg: 0.1055  loss_rpn_cls: 0.09752  loss_rpn_loc: 0.06321  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:45:13] d2.utils.events INFO:  eta: 0:04:31  iter: 9619  total_loss: 0.3014  loss_cls: 0.04687  loss_box_reg: 0.0908  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.06211  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:45:28] d2.utils.events INFO:  eta: 0:04:16  iter: 9639  total_loss: 0.3426  loss_cls: 0.04842  loss_box_reg: 0.09589  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.06688  time: 0.7150  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:45:42] d2.utils.events INFO:  eta: 0:04:02  iter: 9659  total_loss: 0.3637  loss_cls: 0.05514  loss_box_reg: 0.09892  loss_rpn_cls: 0.09688  loss_rpn_loc: 0.1012  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:45:56] d2.utils.events INFO:  eta: 0:03:48  iter: 9679  total_loss: 0.3714  loss_cls: 0.05223  loss_box_reg: 0.1053  loss_rpn_cls: 0.08491  loss_rpn_loc: 0.1009  time: 0.7151  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 17:46:11] d2.utils.events INFO:  eta: 0:03:34  iter: 9699  total_loss: 0.3713  loss_cls: 0.04807  loss_box_reg: 0.1069  loss_rpn_cls: 0.09478  loss_rpn_loc: 0.08063  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:46:25] d2.utils.events INFO:  eta: 0:03:20  iter: 9719  total_loss: 0.3405  loss_cls: 0.04685  loss_box_reg: 0.09814  loss_rpn_cls: 0.09822  loss_rpn_loc: 0.09452  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:46:39] d2.utils.events INFO:  eta: 0:03:05  iter: 9739  total_loss: 0.3104  loss_cls: 0.03765  loss_box_reg: 0.09148  loss_rpn_cls: 0.09159  loss_rpn_loc: 0.07211  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:46:54] d2.utils.events INFO:  eta: 0:02:51  iter: 9759  total_loss: 0.4098  loss_cls: 0.05164  loss_box_reg: 0.102  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1422  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:47:08] d2.utils.events INFO:  eta: 0:02:37  iter: 9779  total_loss: 0.3534  loss_cls: 0.056  loss_box_reg: 0.09816  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.08559  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:47:23] d2.utils.events INFO:  eta: 0:02:22  iter: 9799  total_loss: 0.3351  loss_cls: 0.04594  loss_box_reg: 0.09761  loss_rpn_cls: 0.09127  loss_rpn_loc: 0.101  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:47:37] d2.utils.events INFO:  eta: 0:02:08  iter: 9819  total_loss: 0.4263  loss_cls: 0.05415  loss_box_reg: 0.1092  loss_rpn_cls: 0.1234  loss_rpn_loc: 0.08638  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:47:51] d2.utils.events INFO:  eta: 0:01:54  iter: 9839  total_loss: 0.3213  loss_cls: 0.04981  loss_box_reg: 0.09439  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.06731  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:48:05] d2.utils.events INFO:  eta: 0:01:40  iter: 9859  total_loss: 0.3611  loss_cls: 0.04625  loss_box_reg: 0.09269  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.0927  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:48:20] d2.utils.events INFO:  eta: 0:01:25  iter: 9879  total_loss: 0.4085  loss_cls: 0.04964  loss_box_reg: 0.09098  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.08113  time: 0.7151  data_time: 0.0030  lr: 0.02  max_mem: 8272M
[11/16 17:48:34] d2.utils.events INFO:  eta: 0:01:11  iter: 9899  total_loss: 0.3613  loss_cls: 0.04708  loss_box_reg: 0.09971  loss_rpn_cls: 0.08763  loss_rpn_loc: 0.1068  time: 0.7151  data_time: 0.0031  lr: 0.02  max_mem: 8272M
[11/16 17:48:48] d2.utils.events INFO:  eta: 0:00:57  iter: 9919  total_loss: 0.3263  loss_cls: 0.04706  loss_box_reg: 0.0951  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.07611  time: 0.7151  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:49:03] d2.utils.events INFO:  eta: 0:00:42  iter: 9939  total_loss: 0.3946  loss_cls: 0.05603  loss_box_reg: 0.1166  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.09175  time: 0.7151  data_time: 0.0026  lr: 0.02  max_mem: 8272M
[11/16 17:49:17] d2.utils.events INFO:  eta: 0:00:28  iter: 9959  total_loss: 0.3308  loss_cls: 0.05176  loss_box_reg: 0.08408  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.0737  time: 0.7151  data_time: 0.0027  lr: 0.02  max_mem: 8272M
[11/16 17:49:31] d2.utils.events INFO:  eta: 0:00:14  iter: 9979  total_loss: 0.3757  loss_cls: 0.04454  loss_box_reg: 0.09546  loss_rpn_cls: 0.09852  loss_rpn_loc: 0.08989  time: 0.7150  data_time: 0.0028  lr: 0.02  max_mem: 8272M
[11/16 17:49:45] d2.engine.hooks INFO: Running precise-BN for 200 iterations...  Note that this could produce different statistics every time.
[11/16 17:49:45] fvcore.nn.precise_bn INFO: Computing precise BN statistics for 43 BN layers ...
[11/16 17:50:10] d2.engine.hooks INFO: Running precise-BN ... 100/200 iterations.
[11/16 17:50:35] d2.engine.hooks INFO: Running precise-BN ... 200/200 iterations.
[11/16 17:50:36] fvcore.common.checkpoint INFO: Saving checkpoint to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/model_0009999.pth
[11/16 17:50:36] fvcore.common.checkpoint INFO: Saving checkpoint to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/model_final.pth
[11/16 17:50:36] d2.utils.events INFO:  eta: 0:00:00  iter: 9999  total_loss: 0.3715  loss_cls: 0.04345  loss_box_reg: 0.08819  loss_rpn_cls: 0.09486  loss_rpn_loc: 0.1037  time: 0.7151  data_time: 0.0029  lr: 0.02  max_mem: 8272M
[11/16 17:50:36] d2.engine.hooks INFO: Overall training speed: 9998 iterations in 1:59:09 (0.7151 s / it)
[11/16 17:50:36] d2.engine.hooks INFO: Total training time: 2:05:25 (0:06:16 on hooks)
[11/16 17:50:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 17:50:36] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[11/16 17:50:37] d2.data.common INFO: Serialized dataset takes 1.61 MiB
[11/16 17:50:37] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[11/16 17:50:38] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0008 s/iter. Inference: 0.0680 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:05:40
[11/16 17:50:43] d2.evaluation.evaluator INFO: Inference done 93/4952. Dataloading: 0.0009 s/iter. Inference: 0.0608 s/iter. Eval: 0.0002 s/iter. Total: 0.0620 s/iter. ETA=0:05:01
[11/16 17:50:48] d2.evaluation.evaluator INFO: Inference done 175/4952. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0002 s/iter. Total: 0.0618 s/iter. ETA=0:04:55
[11/16 17:50:53] d2.evaluation.evaluator INFO: Inference done 253/4952. Dataloading: 0.0009 s/iter. Inference: 0.0615 s/iter. Eval: 0.0002 s/iter. Total: 0.0627 s/iter. ETA=0:04:54
[11/16 17:50:58] d2.evaluation.evaluator INFO: Inference done 333/4952. Dataloading: 0.0009 s/iter. Inference: 0.0616 s/iter. Eval: 0.0002 s/iter. Total: 0.0627 s/iter. ETA=0:04:49
[11/16 17:51:03] d2.evaluation.evaluator INFO: Inference done 415/4952. Dataloading: 0.0009 s/iter. Inference: 0.0613 s/iter. Eval: 0.0002 s/iter. Total: 0.0625 s/iter. ETA=0:04:43
[11/16 17:51:08] d2.evaluation.evaluator INFO: Inference done 499/4952. Dataloading: 0.0009 s/iter. Inference: 0.0610 s/iter. Eval: 0.0002 s/iter. Total: 0.0621 s/iter. ETA=0:04:36
[11/16 17:51:13] d2.evaluation.evaluator INFO: Inference done 581/4952. Dataloading: 0.0009 s/iter. Inference: 0.0609 s/iter. Eval: 0.0002 s/iter. Total: 0.0620 s/iter. ETA=0:04:31
[11/16 17:51:18] d2.evaluation.evaluator INFO: Inference done 661/4952. Dataloading: 0.0009 s/iter. Inference: 0.0610 s/iter. Eval: 0.0002 s/iter. Total: 0.0622 s/iter. ETA=0:04:26
[11/16 17:51:23] d2.evaluation.evaluator INFO: Inference done 744/4952. Dataloading: 0.0009 s/iter. Inference: 0.0608 s/iter. Eval: 0.0002 s/iter. Total: 0.0620 s/iter. ETA=0:04:20
[11/16 17:51:28] d2.evaluation.evaluator INFO: Inference done 824/4952. Dataloading: 0.0009 s/iter. Inference: 0.0609 s/iter. Eval: 0.0002 s/iter. Total: 0.0620 s/iter. ETA=0:04:16
[11/16 17:51:33] d2.evaluation.evaluator INFO: Inference done 904/4952. Dataloading: 0.0009 s/iter. Inference: 0.0610 s/iter. Eval: 0.0002 s/iter. Total: 0.0621 s/iter. ETA=0:04:11
[11/16 17:51:38] d2.evaluation.evaluator INFO: Inference done 989/4952. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.0002 s/iter. Total: 0.0619 s/iter. ETA=0:04:05
[11/16 17:51:43] d2.evaluation.evaluator INFO: Inference done 1073/4952. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0002 s/iter. Total: 0.0618 s/iter. ETA=0:03:59
[11/16 17:51:48] d2.evaluation.evaluator INFO: Inference done 1153/4952. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.0002 s/iter. Total: 0.0618 s/iter. ETA=0:03:54
[11/16 17:51:53] d2.evaluation.evaluator INFO: Inference done 1235/4952. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.0002 s/iter. Total: 0.0618 s/iter. ETA=0:03:49
[11/16 17:51:58] d2.evaluation.evaluator INFO: Inference done 1319/4952. Dataloading: 0.0009 s/iter. Inference: 0.0605 s/iter. Eval: 0.0002 s/iter. Total: 0.0617 s/iter. ETA=0:03:44
[11/16 17:52:03] d2.evaluation.evaluator INFO: Inference done 1396/4952. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.0002 s/iter. Total: 0.0619 s/iter. ETA=0:03:39
[11/16 17:52:08] d2.evaluation.evaluator INFO: Inference done 1481/4952. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0002 s/iter. Total: 0.0617 s/iter. ETA=0:03:34
[11/16 17:52:13] d2.evaluation.evaluator INFO: Inference done 1559/4952. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.0002 s/iter. Total: 0.0619 s/iter. ETA=0:03:29
[11/16 17:52:18] d2.evaluation.evaluator INFO: Inference done 1645/4952. Dataloading: 0.0009 s/iter. Inference: 0.0605 s/iter. Eval: 0.0002 s/iter. Total: 0.0617 s/iter. ETA=0:03:24
[11/16 17:52:23] d2.evaluation.evaluator INFO: Inference done 1727/4952. Dataloading: 0.0009 s/iter. Inference: 0.0605 s/iter. Eval: 0.0002 s/iter. Total: 0.0617 s/iter. ETA=0:03:18
[11/16 17:52:28] d2.evaluation.evaluator INFO: Inference done 1805/4952. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0002 s/iter. Total: 0.0618 s/iter. ETA=0:03:14
[11/16 17:52:33] d2.evaluation.evaluator INFO: Inference done 1889/4952. Dataloading: 0.0009 s/iter. Inference: 0.0605 s/iter. Eval: 0.0002 s/iter. Total: 0.0617 s/iter. ETA=0:03:08
[11/16 17:52:38] d2.evaluation.evaluator INFO: Inference done 1973/4952. Dataloading: 0.0009 s/iter. Inference: 0.0605 s/iter. Eval: 0.0002 s/iter. Total: 0.0616 s/iter. ETA=0:03:03
[11/16 17:52:43] d2.evaluation.evaluator INFO: Inference done 2056/4952. Dataloading: 0.0009 s/iter. Inference: 0.0604 s/iter. Eval: 0.0002 s/iter. Total: 0.0616 s/iter. ETA=0:02:58
[11/16 17:52:48] d2.evaluation.evaluator INFO: Inference done 2141/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0615 s/iter. ETA=0:02:52
[11/16 17:52:53] d2.evaluation.evaluator INFO: Inference done 2222/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0615 s/iter. ETA=0:02:47
[11/16 17:52:58] d2.evaluation.evaluator INFO: Inference done 2306/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0614 s/iter. ETA=0:02:42
[11/16 17:53:03] d2.evaluation.evaluator INFO: Inference done 2387/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0615 s/iter. ETA=0:02:37
[11/16 17:53:09] d2.evaluation.evaluator INFO: Inference done 2469/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0615 s/iter. ETA=0:02:32
[11/16 17:53:14] d2.evaluation.evaluator INFO: Inference done 2553/4952. Dataloading: 0.0009 s/iter. Inference: 0.0602 s/iter. Eval: 0.0002 s/iter. Total: 0.0614 s/iter. ETA=0:02:27
[11/16 17:53:19] d2.evaluation.evaluator INFO: Inference done 2632/4952. Dataloading: 0.0009 s/iter. Inference: 0.0603 s/iter. Eval: 0.0002 s/iter. Total: 0.0615 s/iter. ETA=0:02:22
[11/16 17:53:24] d2.evaluation.evaluator INFO: Inference done 2717/4952. Dataloading: 0.0009 s/iter. Inference: 0.0602 s/iter. Eval: 0.0002 s/iter. Total: 0.0614 s/iter. ETA=0:02:17
[11/16 17:53:29] d2.evaluation.evaluator INFO: Inference done 2800/4952. Dataloading: 0.0009 s/iter. Inference: 0.0602 s/iter. Eval: 0.0002 s/iter. Total: 0.0614 s/iter. ETA=0:02:12
[11/16 17:53:34] d2.evaluation.evaluator INFO: Inference done 2884/4952. Dataloading: 0.0009 s/iter. Inference: 0.0602 s/iter. Eval: 0.0002 s/iter. Total: 0.0613 s/iter. ETA=0:02:06
[11/16 17:53:39] d2.evaluation.evaluator INFO: Inference done 2969/4952. Dataloading: 0.0009 s/iter. Inference: 0.0601 s/iter. Eval: 0.0002 s/iter. Total: 0.0613 s/iter. ETA=0:02:01
[11/16 17:53:44] d2.evaluation.evaluator INFO: Inference done 3054/4952. Dataloading: 0.0009 s/iter. Inference: 0.0601 s/iter. Eval: 0.0002 s/iter. Total: 0.0612 s/iter. ETA=0:01:56
[11/16 17:53:49] d2.evaluation.evaluator INFO: Inference done 3138/4952. Dataloading: 0.0009 s/iter. Inference: 0.0600 s/iter. Eval: 0.0002 s/iter. Total: 0.0612 s/iter. ETA=0:01:50
[11/16 17:53:54] d2.evaluation.evaluator INFO: Inference done 3218/4952. Dataloading: 0.0010 s/iter. Inference: 0.0601 s/iter. Eval: 0.0002 s/iter. Total: 0.0613 s/iter. ETA=0:01:46
[11/16 17:53:59] d2.evaluation.evaluator INFO: Inference done 3302/4952. Dataloading: 0.0010 s/iter. Inference: 0.0601 s/iter. Eval: 0.0002 s/iter. Total: 0.0612 s/iter. ETA=0:01:41
[11/16 17:54:04] d2.evaluation.evaluator INFO: Inference done 3387/4952. Dataloading: 0.0010 s/iter. Inference: 0.0600 s/iter. Eval: 0.0002 s/iter. Total: 0.0612 s/iter. ETA=0:01:35
[11/16 17:54:09] d2.evaluation.evaluator INFO: Inference done 3470/4952. Dataloading: 0.0010 s/iter. Inference: 0.0600 s/iter. Eval: 0.0002 s/iter. Total: 0.0611 s/iter. ETA=0:01:30
[11/16 17:54:14] d2.evaluation.evaluator INFO: Inference done 3556/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0611 s/iter. ETA=0:01:25
[11/16 17:54:19] d2.evaluation.evaluator INFO: Inference done 3640/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:01:20
[11/16 17:54:24] d2.evaluation.evaluator INFO: Inference done 3724/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:01:14
[11/16 17:54:29] d2.evaluation.evaluator INFO: Inference done 3805/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:01:10
[11/16 17:54:34] d2.evaluation.evaluator INFO: Inference done 3888/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0611 s/iter. ETA=0:01:04
[11/16 17:54:39] d2.evaluation.evaluator INFO: Inference done 3973/4952. Dataloading: 0.0010 s/iter. Inference: 0.0598 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:59
[11/16 17:54:44] d2.evaluation.evaluator INFO: Inference done 4057/4952. Dataloading: 0.0010 s/iter. Inference: 0.0598 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:54
[11/16 17:54:49] d2.evaluation.evaluator INFO: Inference done 4137/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:49
[11/16 17:54:54] d2.evaluation.evaluator INFO: Inference done 4220/4952. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:44
[11/16 17:54:59] d2.evaluation.evaluator INFO: Inference done 4306/4952. Dataloading: 0.0010 s/iter. Inference: 0.0598 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:39
[11/16 17:55:04] d2.evaluation.evaluator INFO: Inference done 4389/4952. Dataloading: 0.0010 s/iter. Inference: 0.0598 s/iter. Eval: 0.0002 s/iter. Total: 0.0610 s/iter. ETA=0:00:34
[11/16 17:55:09] d2.evaluation.evaluator INFO: Inference done 4476/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:28
[11/16 17:55:14] d2.evaluation.evaluator INFO: Inference done 4558/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:23
[11/16 17:55:19] d2.evaluation.evaluator INFO: Inference done 4640/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:19
[11/16 17:55:24] d2.evaluation.evaluator INFO: Inference done 4725/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:13
[11/16 17:55:29] d2.evaluation.evaluator INFO: Inference done 4810/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:08
[11/16 17:55:35] d2.evaluation.evaluator INFO: Inference done 4891/4952. Dataloading: 0.0010 s/iter. Inference: 0.0597 s/iter. Eval: 0.0002 s/iter. Total: 0.0609 s/iter. ETA=0:00:03
[11/16 17:55:38] d2.evaluation.evaluator INFO: Total inference time: 0:05:01.157764 (0.060877 s / iter per device, on 1 devices)
[11/16 17:55:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:55 (0.059711 s / iter per device, on 1 devices)
[11/16 17:55:38] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 17:55:38] d2.evaluation.coco_evaluation INFO: Saving results to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/inference/coco_instances_results.json
[11/16 17:55:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 17:55:39] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 17:55:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.35 seconds.
[11/16 17:55:39] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 17:55:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.09 seconds.
[11/16 17:55:39] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.326 | 27.092 | 4.255  | 0.050 | 1.558 | 13.909 |
[11/16 17:55:39] d2.engine.defaults INFO: Evaluation results for voc_2007_test_CAD_coco_style in csv format:
[11/16 17:55:39] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 17:55:39] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 17:55:39] d2.evaluation.testing INFO: copypaste: 9.3257,27.0923,4.2553,0.0495,1.5579,13.9091
[11/16 17:58:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/16 17:58:19] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.5 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.2
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.1 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.8.2 @/home/yanghao/anaconda3/envs/lost2/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20220512
iopath                  0.1.8
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/16 17:58:19] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml', dist_url='tcp://127.0.0.1:50167', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['DATALOADER.NUM_WORKERS', '6', 'MODEL.WEIGHTS', './outputs/RN50_DINO_FRCNN_VOC07_CAD/model_final.pth', 'OUTPUT_DIR', './outputs/RN50_DINO_FRCNN_VOC07_CAD/', 'DATASETS.TEST', '("voc_2007_trainval_CAD_coco_style", )'], resume=True)
[11/16 17:58:19] detectron2 INFO: Contents of args.config_file=./configs/LOST/RN50_DINO_FRCNN_VOC07_CAD.yaml:
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  WEIGHTS: "/path/to/dino/weights.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    NORM: "BN"
  ROI_HEADS:
    NAME: "Res5ROIHeadsExtraNorm"
    NUM_CLASSES: 1
    SCORE_THRESH_TEST: 0.01
    NMS_THRESH_TEST: 0.4
  BACKBONE:
    FREEZE_AT: 2
  ROI_BOX_HEAD:
    NORM: "BN" # RGB Mean and Std
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
  FORMAT: "RGB"
DATASETS:
  TRAIN: ('voc_2007_trainval_LOST_CAD', )
  TEST: ('voc_2007_test_CAD_coco_style', )
TEST:
  EVAL_PERIOD: 5000
  PRECISE_BN:
    ENABLED: True
SOLVER:
  STEPS: (18000, 22000)
  MAX_ITER: 10000
  WARMUP_ITERS: 100 # Maybe needs tuning.
  IMS_PER_BATCH: 2
  BASE_LR: 0.02 # Maybe it will need some tuning. MoCo used 0.02.
OUTPUT_DIR: "./outputs/RN50_DINO_FRCNN_VOC07_CAD"

[11/16 17:58:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 6
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - voc_2007_trainval_CAD_coco_style
  TRAIN:
  - voc_2007_trainval_LOST_CAD
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: BN
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeadsExtraNorm
    NMS_THRESH_TEST: 0.4
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.01
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./outputs/RN50_DINO_FRCNN_VOC07_CAD/model_final.pth
OUTPUT_DIR: ./outputs/RN50_DINO_FRCNN_VOC07_CAD/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 18000
  - 22000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: true
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 17:58:19] detectron2 INFO: Full config saved to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/config.yaml
[11/16 17:58:19] d2.utils.env INFO: Using a generated random seed 19556249
[11/16 17:58:19] d2.modeling.roi_heads.roi_heads WARNING: The behavior of _build_res5_block may change. Please do not depend on private methods.
[11/16 17:58:21] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeadsExtraNorm(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)
    )
  )
)
[11/16 17:58:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./outputs/RN50_DINO_FRCNN_VOC07_CAD/model_final.pth ...
[11/16 17:58:21] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|   object   | 12608        |
|            |              |[0m
[11/16 17:58:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 17:58:21] d2.data.common INFO: Serializing 5011 elements to byte tensors and concatenating them all ...
[11/16 17:58:21] d2.data.common INFO: Serialized dataset takes 1.65 MiB
[11/16 17:58:21] d2.evaluation.coco_evaluation INFO: 'voc_2007_trainval_CAD_coco_style' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[11/16 17:58:21] d2.data.datasets.coco INFO: Converting annotations of dataset 'voc_2007_trainval_CAD_coco_style' to COCO format ...)
[11/16 17:58:22] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[11/16 17:58:23] d2.data.datasets.coco INFO: Conversion finished, #images: 5011, #annotations: 12608
[11/16 17:58:23] d2.data.datasets.coco INFO: Caching COCO format annotations at './outputs/RN50_DINO_FRCNN_VOC07_CAD/inference/voc_2007_trainval_CAD_coco_style_coco_format.json' ...
[11/16 17:58:23] d2.evaluation.evaluator INFO: Start inference on 5011 batches
[11/16 17:58:24] d2.evaluation.evaluator INFO: Inference done 11/5011. Dataloading: 0.0008 s/iter. Inference: 0.0525 s/iter. Eval: 0.0001 s/iter. Total: 0.0535 s/iter. ETA=0:04:27
[11/16 17:58:29] d2.evaluation.evaluator INFO: Inference done 98/5011. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.0001 s/iter. Total: 0.0574 s/iter. ETA=0:04:42
[11/16 17:58:34] d2.evaluation.evaluator INFO: Inference done 184/5011. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.0001 s/iter. Total: 0.0580 s/iter. ETA=0:04:40
[11/16 17:58:39] d2.evaluation.evaluator INFO: Inference done 272/5011. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.0001 s/iter. Total: 0.0578 s/iter. ETA=0:04:33
[11/16 17:58:44] d2.evaluation.evaluator INFO: Inference done 359/5011. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.0001 s/iter. Total: 0.0577 s/iter. ETA=0:04:28
[11/16 17:58:49] d2.evaluation.evaluator INFO: Inference done 444/5011. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.0001 s/iter. Total: 0.0580 s/iter. ETA=0:04:24
[11/16 17:58:54] d2.evaluation.evaluator INFO: Inference done 532/5011. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.0001 s/iter. Total: 0.0579 s/iter. ETA=0:04:19
[11/16 17:59:00] d2.evaluation.evaluator INFO: Inference done 616/5011. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.0001 s/iter. Total: 0.0582 s/iter. ETA=0:04:15
[11/16 17:59:05] d2.evaluation.evaluator INFO: Inference done 702/5011. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.0001 s/iter. Total: 0.0582 s/iter. ETA=0:04:10
[11/16 17:59:10] d2.evaluation.evaluator INFO: Inference done 785/5011. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.0001 s/iter. Total: 0.0585 s/iter. ETA=0:04:07
[11/16 17:59:15] d2.evaluation.evaluator INFO: Inference done 867/5011. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.0001 s/iter. Total: 0.0587 s/iter. ETA=0:04:03
[11/16 17:59:20] d2.evaluation.evaluator INFO: Inference done 954/5011. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.0001 s/iter. Total: 0.0586 s/iter. ETA=0:03:57
[11/16 17:59:25] d2.evaluation.evaluator INFO: Inference done 1038/5011. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.0001 s/iter. Total: 0.0587 s/iter. ETA=0:03:53
[11/16 17:59:30] d2.evaluation.evaluator INFO: Inference done 1121/5011. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.0001 s/iter. Total: 0.0589 s/iter. ETA=0:03:48
[11/16 17:59:35] d2.evaluation.evaluator INFO: Inference done 1202/5011. Dataloading: 0.0009 s/iter. Inference: 0.0579 s/iter. Eval: 0.0001 s/iter. Total: 0.0591 s/iter. ETA=0:03:44
[11/16 17:59:40] d2.evaluation.evaluator INFO: Inference done 1282/5011. Dataloading: 0.0009 s/iter. Inference: 0.0582 s/iter. Eval: 0.0001 s/iter. Total: 0.0593 s/iter. ETA=0:03:41
[11/16 17:59:45] d2.evaluation.evaluator INFO: Inference done 1363/5011. Dataloading: 0.0009 s/iter. Inference: 0.0583 s/iter. Eval: 0.0001 s/iter. Total: 0.0595 s/iter. ETA=0:03:36
[11/16 17:59:50] d2.evaluation.evaluator INFO: Inference done 1442/5011. Dataloading: 0.0009 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0597 s/iter. ETA=0:03:33
[11/16 17:59:55] d2.evaluation.evaluator INFO: Inference done 1527/5011. Dataloading: 0.0009 s/iter. Inference: 0.0585 s/iter. Eval: 0.0001 s/iter. Total: 0.0597 s/iter. ETA=0:03:27
[11/16 18:00:00] d2.evaluation.evaluator INFO: Inference done 1613/5011. Dataloading: 0.0009 s/iter. Inference: 0.0585 s/iter. Eval: 0.0001 s/iter. Total: 0.0596 s/iter. ETA=0:03:22
[11/16 18:00:05] d2.evaluation.evaluator INFO: Inference done 1700/5011. Dataloading: 0.0009 s/iter. Inference: 0.0584 s/iter. Eval: 0.0001 s/iter. Total: 0.0595 s/iter. ETA=0:03:16
[11/16 18:00:10] d2.evaluation.evaluator INFO: Inference done 1787/5011. Dataloading: 0.0009 s/iter. Inference: 0.0583 s/iter. Eval: 0.0001 s/iter. Total: 0.0594 s/iter. ETA=0:03:11
[11/16 18:00:15] d2.evaluation.evaluator INFO: Inference done 1868/5011. Dataloading: 0.0009 s/iter. Inference: 0.0584 s/iter. Eval: 0.0001 s/iter. Total: 0.0595 s/iter. ETA=0:03:07
[11/16 18:00:20] d2.evaluation.evaluator INFO: Inference done 1951/5011. Dataloading: 0.0009 s/iter. Inference: 0.0584 s/iter. Eval: 0.0001 s/iter. Total: 0.0596 s/iter. ETA=0:03:02
[11/16 18:00:25] d2.evaluation.evaluator INFO: Inference done 2035/5011. Dataloading: 0.0009 s/iter. Inference: 0.0585 s/iter. Eval: 0.0001 s/iter. Total: 0.0596 s/iter. ETA=0:02:57
[11/16 18:00:30] d2.evaluation.evaluator INFO: Inference done 2119/5011. Dataloading: 0.0009 s/iter. Inference: 0.0585 s/iter. Eval: 0.0001 s/iter. Total: 0.0596 s/iter. ETA=0:02:52
[11/16 18:00:35] d2.evaluation.evaluator INFO: Inference done 2200/5011. Dataloading: 0.0009 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0597 s/iter. ETA=0:02:47
[11/16 18:00:40] d2.evaluation.evaluator INFO: Inference done 2283/5011. Dataloading: 0.0009 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0597 s/iter. ETA=0:02:42
[11/16 18:00:45] d2.evaluation.evaluator INFO: Inference done 2365/5011. Dataloading: 0.0010 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0598 s/iter. ETA=0:02:38
[11/16 18:00:50] d2.evaluation.evaluator INFO: Inference done 2447/5011. Dataloading: 0.0010 s/iter. Inference: 0.0587 s/iter. Eval: 0.0001 s/iter. Total: 0.0598 s/iter. ETA=0:02:33
[11/16 18:00:55] d2.evaluation.evaluator INFO: Inference done 2533/5011. Dataloading: 0.0010 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0598 s/iter. ETA=0:02:28
[11/16 18:01:00] d2.evaluation.evaluator INFO: Inference done 2618/5011. Dataloading: 0.0010 s/iter. Inference: 0.0586 s/iter. Eval: 0.0001 s/iter. Total: 0.0598 s/iter. ETA=0:02:23
[11/16 18:01:05] d2.evaluation.evaluator INFO: Inference done 2694/5011. Dataloading: 0.0010 s/iter. Inference: 0.0588 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:02:18
[11/16 18:01:10] d2.evaluation.evaluator INFO: Inference done 2779/5011. Dataloading: 0.0010 s/iter. Inference: 0.0588 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:02:13
[11/16 18:01:15] d2.evaluation.evaluator INFO: Inference done 2858/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:02:09
[11/16 18:01:20] d2.evaluation.evaluator INFO: Inference done 2944/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:02:04
[11/16 18:01:25] d2.evaluation.evaluator INFO: Inference done 3029/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:01:58
[11/16 18:01:30] d2.evaluation.evaluator INFO: Inference done 3112/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:01:53
[11/16 18:01:35] d2.evaluation.evaluator INFO: Inference done 3193/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:01:49
[11/16 18:01:40] d2.evaluation.evaluator INFO: Inference done 3278/5011. Dataloading: 0.0010 s/iter. Inference: 0.0589 s/iter. Eval: 0.0001 s/iter. Total: 0.0600 s/iter. ETA=0:01:44
[11/16 18:01:46] d2.evaluation.evaluator INFO: Inference done 3359/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:01:39
[11/16 18:01:51] d2.evaluation.evaluator INFO: Inference done 3443/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:01:34
[11/16 18:01:56] d2.evaluation.evaluator INFO: Inference done 3521/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:29
[11/16 18:02:01] d2.evaluation.evaluator INFO: Inference done 3605/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:24
[11/16 18:02:06] d2.evaluation.evaluator INFO: Inference done 3688/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:19
[11/16 18:02:11] d2.evaluation.evaluator INFO: Inference done 3771/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:14
[11/16 18:02:16] d2.evaluation.evaluator INFO: Inference done 3857/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:09
[11/16 18:02:21] d2.evaluation.evaluator INFO: Inference done 3941/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:01:04
[11/16 18:02:26] d2.evaluation.evaluator INFO: Inference done 4025/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:59
[11/16 18:02:31] d2.evaluation.evaluator INFO: Inference done 4109/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:54
[11/16 18:02:36] d2.evaluation.evaluator INFO: Inference done 4195/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:49
[11/16 18:02:41] d2.evaluation.evaluator INFO: Inference done 4278/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:44
[11/16 18:02:46] d2.evaluation.evaluator INFO: Inference done 4360/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:39
[11/16 18:02:51] d2.evaluation.evaluator INFO: Inference done 4444/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:34
[11/16 18:02:56] d2.evaluation.evaluator INFO: Inference done 4526/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:29
[11/16 18:03:01] d2.evaluation.evaluator INFO: Inference done 4611/5011. Dataloading: 0.0010 s/iter. Inference: 0.0590 s/iter. Eval: 0.0001 s/iter. Total: 0.0601 s/iter. ETA=0:00:24
[11/16 18:03:06] d2.evaluation.evaluator INFO: Inference done 4685/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0603 s/iter. ETA=0:00:19
[11/16 18:03:11] d2.evaluation.evaluator INFO: Inference done 4770/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:00:14
[11/16 18:03:16] d2.evaluation.evaluator INFO: Inference done 4856/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:00:09
[11/16 18:03:21] d2.evaluation.evaluator INFO: Inference done 4938/5011. Dataloading: 0.0010 s/iter. Inference: 0.0591 s/iter. Eval: 0.0001 s/iter. Total: 0.0602 s/iter. ETA=0:00:04
[11/16 18:03:25] d2.evaluation.evaluator INFO: Total inference time: 0:05:01.445649 (0.060217 s / iter per device, on 1 devices)
[11/16 18:03:25] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:55 (0.059065 s / iter per device, on 1 devices)
[11/16 18:03:26] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 18:03:26] d2.evaluation.coco_evaluation INFO: Saving results to ./outputs/RN50_DINO_FRCNN_VOC07_CAD/inference/coco_instances_results.json
[11/16 18:03:26] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 18:03:26] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 18:03:26] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.29 seconds.
[11/16 18:03:26] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 18:03:26] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.10 seconds.
[11/16 18:03:26] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.336 | 26.313 | 4.771  | 0.014 | 1.507 | 14.131 |
[11/16 18:03:26] d2.engine.defaults INFO: Evaluation results for voc_2007_trainval_CAD_coco_style in csv format:
[11/16 18:03:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 18:03:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 18:03:26] d2.evaluation.testing INFO: copypaste: 9.3356,26.3125,4.7707,0.0141,1.5072,14.1308
